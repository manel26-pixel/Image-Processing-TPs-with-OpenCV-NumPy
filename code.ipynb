{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV + NumPy Cheatsheet\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ—¾ï¸ 1. Image I/O & Properties\n",
    "\n",
    "| Task | Code / Explanation |\n",
    "|------|--------------------|\n",
    "| Read a color image | `img = cv2.imread(image_path)` |\n",
    "| Read grayscale image | `img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)` |\n",
    "| Get image dimensions | `h, w, c = img.shape` (height, width, channels) |\n",
    "| Check image type | `img.dtype` |\n",
    "| Convert to float | `img = img.astype(np.float32)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¨ 2. Image Initialization\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Create empty (zeros) image | `img = np.zeros((h, w, c), np.uint8)` |\n",
    "| Clone shape & type | `img2 = np.zeros_like(img)` |\n",
    "| Create image filled with 1s | `img = np.ones((h, w), np.float32)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”€ 3. Image Manipulation\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Invert image | `img_inv = 255 - img` |\n",
    "| Normalize values to [0, 1] | `img = img / 255.0` |\n",
    "| Custom normalization | `img[y,x] = ((img[y,x] - min) / (max - min)) * 255` |\n",
    "| Resize image | `resized = cv2.resize(img, (width, height))` |\n",
    "| Concatenate images | `cv2.hconcat([img1, img2])` (horizontal) |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ–›ï¸ 4. Filtering & Convolution\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| 2D Convolution | `cv2.filter2D(img, -1, kernel)` |\n",
    "| Normalize result | `cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽº 5. Histogram & Plotting (Matplotlib)\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Init histogram | `histo = np.zeros((256, 1), np.uint16)` |\n",
    "| Calculate histogram | `cv2.calcHist([img], [0], None, [256], [0,256])` |\n",
    "| Plot histogram | `plt.plot(histo); plt.xlim([0, 255]); plt.show()` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”± 6. Trackbars (Interactive Sliders)\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Create trackbar | `cv2.createTrackbar(\"thresh\", \"window\", 0, 255, callback_fn)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§¬ 7. Morphological Operations\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Thresholding | `cv2.threshold(img, 128, 255, cv2.THRESH_BINARY, img)` |\n",
    "| Erode | `cv2.erode(img, kernel)` |\n",
    "| Dilate | `cv2.dilate(img, kernel)` |\n",
    "| MorphologyEx (e.g., Gradient) | `cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)` |\n",
    "| Kernel structure | `cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” 8. Gradient & Edge Detection\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Compute gradients | `grad_x = img[:, :-1] - img[:, 1:]` |\n",
    "| Pad arrays | `grad_x = np.pad(grad_x, ((0,0),(0,1)), mode='constant')` |\n",
    "| Gradient magnitude | `grad = np.sqrt(grad_x**2 + grad_y**2)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¥ 9. Video & Camera Input\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| From webcam | `cv2.VideoCapture(0)` |\n",
    "| From file | `cv2.VideoCapture('video.avi')` |\n",
    "| From phone | `cv2.VideoCapture(\"http://IP:PORT/video\")` |\n",
    "| Get frame size | `w = int(cap.get(3)), h = int(cap.get(4))` |\n",
    "| Read frame | `ret, frame = cap.read()` |\n",
    "| Flip frame | `cv2.flip(frame, 1, frame)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“€ 10. Video Output (Recording)\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Define codec | `fourcc = cv2.VideoWriter_fourcc('X','V','I','D')` |\n",
    "| Init writer | `out = cv2.VideoWriter('file.avi', fourcc, 30, (w, h))` |\n",
    "| Write frame | `out.write(frame)` |\n",
    "| Release | `out.release()` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”´ 11. Image Color Spaces\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Split BGR | `img_b[:,:,0], img_g[:,:,1], img_r[:,:,2] = img[:,:,0], img[:,:,1], img[:,:,2]` |\n",
    "| RGB to gray (manual) | `gray = (b + g + r) / 3` or use weights |\n",
    "| BGR to HSV | `img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)` |\n",
    "| BGR to Grayscale | `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”„ 12. Utility / Control Flow\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| Wait for key | `cv2.waitKey(0)` |\n",
    "| Destroy all windows | `cv2.destroyAllWindows()` |\n",
    "| Quit condition | `if cv2.waitKey(20) & 0xFF == ord('q'):` |\n",
    "| Random point | `x, y = randrange(w), randrange(h)` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  13. Data Types in NumPy\n",
    "\n",
    "| Type | Range |\n",
    "|------|--------|\n",
    "| `uint8` | [0, 255] |\n",
    "| `int8` | [-128, 127] |\n",
    "| `uint16` | [0, 65535] |\n",
    "| `int16` | [-32768, 32767] |\n",
    "| `uint32` | [0, 4294967295] |\n",
    "| `int32` | [-2147483648, 2147483647] |\n",
    "| `float32` | ~ [1.2e-38, 3.4e+38] |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 1 â€“ Negative Transformation of an Image '''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image from file\n",
    "image_path = 'sadcat.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: The image couldn't be loaded. Please check the file path.\")\n",
    "    exit(0)\n",
    "else:\n",
    "    # Get image dimensions (height, width, channels)\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    # Create a float32 image with the same shape as the original\n",
    "    imgRes = np.zeros(image.shape, np.float32)\n",
    "\n",
    "    # Compute the negative of the image using vectorized operation\n",
    "    # Subtract each pixel value from 255 (max intensity) to invert the image\n",
    "    imgRes[:] = 255 - image[:]\n",
    "\n",
    "    # Normalize the result to [0, 1] range (optional step depending on use case)\n",
    "    imgRes = imgRes / 255.\n",
    "\n",
    "    # Display the original and the resulting images\n",
    "    cv2.imshow(\"Original Image\", image)\n",
    "    cv2.imshow(\"Negative Image\", imgRes)\n",
    "\n",
    "    # Wait for a key press before closing the image windows\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min pixel value: 0\n",
      "Max pixel value: 127\n"
     ]
    }
   ],
   "source": [
    "''' TP 2 â€“ Manual Normalization of a Grayscale Image '''\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image in grayscale mode\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Simulate an image with low brightness by dividing pixel values by 2\n",
    "img[:] = img[:] / 2\n",
    "\n",
    "# Uncomment to save this darker version if needed\n",
    "# cv2.imwrite(\"img2.jfif\", img)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: The image couldn't be loaded. Please check the file path.\")\n",
    "    exit(0)\n",
    "\n",
    "# Create an empty image to store the normalized result\n",
    "imgNorm = np.zeros(img.shape, np.uint8)\n",
    "\n",
    "# Get the image dimensions\n",
    "h, w = img.shape\n",
    "\n",
    "# Initialize min and max values for normalization\n",
    "min_val = 255\n",
    "max_val = 0\n",
    "\n",
    "# Find the minimum and maximum pixel values in the image\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        if img[y, x] > max_val:\n",
    "            max_val = img[y, x]\n",
    "        if img[y, x] < min_val:\n",
    "            min_val = img[y, x]\n",
    "\n",
    "# Normalize the pixel values to span the full range [0, 255]\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        imgNorm[y, x] = ((img[y, x] - min_val) / (max_val - min_val)) * 255\n",
    "\n",
    "# Print the original min and max values (for verification)\n",
    "print(\"Min pixel value:\", min_val)\n",
    "print(\"Max pixel value:\", max_val)\n",
    "\n",
    "# Display the original (darkened) and normalized images\n",
    "cv2.imshow(\"Original Image (Darkened)\", img)\n",
    "cv2.imshow(\"Normalized Image\", imgNorm)\n",
    "\n",
    "# Wait for a key press and then close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAHHCAYAAACMfE3pAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAc3ZJREFUeJzt3Qd4FNXXBvB3N70HCITeEaQXARERESQiKAgqIioCoiAqRUGwAPqpKFhAKYp/BStNQaVLR+lVepAiPZRAQnrb+Z5zl1l2U0jblvD+nmezu7OzM3dmNjtnz71zr0HTNA1EREREZFdG+y6OiIiIiASDLCIiIiIHYJBFRERE5AAMsoiIiIgcgEEWERERkQMwyCIiIiJyAAZZRERERA7AIIuIiIjIARhkERERETkAgywisot7771X3XT//fcfDAYDZs2a5dRyPPvss6hatapT11mcyDEbN26cq4tBVCwwyCJyEgk25ATm6+uLs2fPZnldApT69eu7pGy3olthf0uwJJ+5y5cvZ/u6BKNdunQp9Hp+/vlnTJo0qdDLISpuPF1dAKJbTUpKCj788EN88cUXKM6qVKmCpKQkeHl5uboolA9yzDw9PfMdZO3fvx9Dhw51WLmIiiJmsoicrHHjxvj6669x7tw5h61Dxn2Xk6Ur6Vk7Dw8Pl5aD8keOWX6DLFdLSEhwdRGIssUgi8jJ3njjDWRkZKhsVm7S09Pxf//3f6hRowZ8fHxU9Y68X7Jh2VX7rFixAnfccQf8/Pzw1VdfYd26dSrYmTdvHt555x1UqFABQUFBePTRRxEbG6uWI9mHMmXKIDAwEH379s2y7JkzZ+K+++5T80gZ6tati+nTp+da9sxtsvSyZHfL3IZq2bJlaNOmDQICAlR5O3fujAMHDmRZx2+//aaq/CQwkPuFCxeiMKQsL730EubPn6+2U/Zjq1atsG/fPvW67NOaNWuq9Ul1o2yjtb/++guPPfYYKleurPZVpUqVMGzYsGwDXn0d1mXPrj2ZyWRSVXH16tVT84aHh+OFF17A1atXC7WteW2TFRcXpz4jUi7ZJvkc3H///di1a5d6XfbDkiVLcPLkyWyP58WLF9G/f39Vbil/o0aN8N1332VZb3R0NJ5++mkEBwcjNDQUffr0wT///JOlXZ/sI/msHjt2DA8++KD6fPTu3Ttf+19fxqlTp9T/jTyW/42pU6eq1+V4y2dePn+SkZVMHVFBFK2fK0TFQLVq1fDMM8+obNaoUaNQvnz5HOd97rnn1AlJgqJXX30VW7duxfjx43Ho0KEsAUVkZCR69eqlTsADBgxA7dq1La/JeyRgkPUdPXpUVVVKNZ7RaFQnazmpbtmyRZ3MpHxjxoyxvFcCKjnBP/zwwyrDsWjRIrz44ovq5D948OA8b/ftt9+OH374wWZaTEwMhg8frk7cOplHTrARERH46KOPkJiYqMpw9913Y/fu3ZYT+J9//okePXqoQEW2T07SEiRWrFgRhSEn6j/++MOybbJsORGPHDkS06ZNU9su+2zChAno168f1qxZYxM4SXkHDRqEUqVKYdu2bWpfnzlzRr2mk6CkZ8+eaNCggVq+LE8CETnRZybHU46LbNsrr7yCEydOYMqUKWpfbNy4MU/VsVeuXMl2uhzD3AwcOBC//PKLCj5lX8t+/vvvv9VnsGnTpnjzzTdVwC7b+Nlnn6n3SNAiJLiRIEw+c/J++WzJfpAgR479kCFDLOV46KGH1P6SfVenTh38/vvv6nOQ048P+XzIZ+Ljjz+Gv79/vva/kB86nTp1wj333KOO5U8//aTKKIGVbJMEbt27d8eXX36p/l8l2JbyE+WLRkROMXPmTE3+5bZv364dO3ZM8/T01F555RXL623bttXq1atneb5nzx41/3PPPWeznNdee01NX7NmjWValSpV1LTly5fbzLt27Vo1vX79+lpqaqpleq9evTSDwaB16tTJZv5WrVqpZVlLTEzMsi0RERFa9erVbaZJ+eWmO3HihFq3bHd2TCaT1qVLFy0wMFA7cOCAmhYXF6eFhoZqAwYMsJk3KipKCwkJsZneuHFjrVy5clpMTIxl2p9//qnWmXkbspN5fwt5r4+Pjyq77quvvlLTy5Ytq127ds0yffTo0Wq69bzZ7avx48erfX3y5EnLtAYNGmgVK1ZU26tbt25dlrL/9ddfatpPP/1ks0w5ztlNz2zs2LFqvpvdOnfunGUfyPt0st8HDx580/XIMrLb55MmTVLL+/HHHy3T5HMonzM57vr+/PXXX9V8Mr8uIyNDu++++7J8hvr06aOmjRo1Ksv68rr/9WV88MEHlmlXr17V/Pz81Lxz5syxTD98+HCWfUKUV6wuJHKB6tWrq6qRGTNm4Pz589nOs3TpUnUvmR5rktHSsyHW5Fe2/LrPjvwSt854tGzZUrXbkkyMNZl++vRplSnQSQZMJxkLuVKtbdu2OH78uHpeUFINunjxYpWlkQyJWLlypcpwSEZO1qPfpF2XlG3t2rVqPtlne/bsUZmOkJAQyzKlGktfVkG1b9/eprpL1iskayZVU5mny37Ibl9JOyEp+1133aX2tWSehLTFk+ooOSZ6xkfIPpXMljXJvsj2yXZZ749mzZqp9+r7Ize//vqr2reZb1KFlxupupMMakHaEMpnuGzZsup46uRzKBm5+Ph4rF+/Xk1bvny5mi4ZWJ1kWW+WKZVsVWZ52f+ZM8XW2ynZX8lkPf7445bpMk1esz7ORHnF6kIiF3nrrbdU1Zi0zZo8eXKW16WNi5xopA2QNTlpyZe+vG7tZlUZ0kbFmh6YSJuVzNOl6kaCJ6luEVIlNXbsWGzevFlVxViT+ayDnLySk6q0ERs9erQKXnT//vuvupf2MNmR9jpC3/ZatWplmUdOinp7oYLIz74S1m2jpI2PVLVKdWPmNlN6QKqXPfNx1adZl132h7zPujrVmrR3ygupEgsLC8syXdpI5Uaq0iSYle2X4E7aQUmAKD8UciPbKsdIPseZq4711/X7cuXKWar9dNntIyHV1tlVC+dl/1tve+nSpbMcU1mutAPLPN1RbeCoeGOQReQicpJ66qmnVDZL2krlJPMXfk6sf8VnltMVfjlNN9caQTUulsyOtJH59NNP1YnW29tbZSik/U1e2vRkJm2KpL2LZGfee+89m9f05UnwKcFkZs646q2g+0ra+Mg2Sfun119/Xe0zyYpIn2jSBqkg+0reIwGWtBfKTuYgwREkqyMXIUgbQGkHN3HiRNVWbsGCBapNkytIo/bMgVt+939BjzNRfjDIInJxNuvHH39UJ63M5KomOTFINkP/5S8uXLigqtTkdUeTRu5ytaFkBqwzPHmtpspMGkJLY2LJxM2ePTvLiVKuohQSWHTo0CHH5ejbrme+Ml8A4ApSBXjkyBF1oYJkenRSLZdd2aUxeGaZp8n+WLVqFVq3bn3TINrRJMskDf7lJtkzafD+/vvvW4KsnH4IyLbu3btXfY6tj/Xhw4ctr+v38pmSTKl1Niu7fVTY/U/kTGyTReRCchKVbJZ0DRAVFWXzmlTLiMw9aUtGSUi3Bo6m/6q3/hUv1S7SrUNByJVqciKUrEiJEiWyvC5tyqRK8IMPPkBaWlqW1y9dumQ56Ut/Y3JCta4GkhPqwYMH4QrZ7St5nLkqWK4mlS4bvv/+e9UuSSftk/SuIqyzSJKhkfZrmUm7OQm2HUnWnbmaTQJg2Qbrrj4kY5Rd+zz5DMvneu7cuTblliv+pE2ZtEPTj7scb7niVieBmd6lgj33P5EzMZNF5GJyubhUj0kGRrpK0El/QtIWRqoT5WQqJyS5JF0Ci27duqFdu3YOL1vHjh1V9aBcXi9dCUhQICdCOdHm1GA/J9JQXwILaYMl2Q256eSEK9skAZZ01yAXBUi25IknnlBVYtLWRt4vGR3pvkBI1wcSaMpl/NKAX6qJ5OQt+9A6eHEWqZ6SoPm1115TVVSyLdLgPLu2PBJEdu3aVW2PdM0g88h2SfBlXXY55rLfZVulob8cD2kgLhk8aRQvAYR07+Eo0keWtFGSdcjnUY6TZNa2b9+OTz75xDKftNWSQEou0mjevLmaTz4zzz//vPoBIdV1O3fuVBcUSHcQ0s5PfjzoFxLIsW/RooW6qEOyV7IvJXuqdz2Rlyrz/Ox/IqfJ83WIRGS3Lhwy0y8pz9ylQFpamvbOO+9o1apV07y8vLRKlSqprgOSk5Nt5pPL5zNfim/dhcP8+fPzVBb9kv9Lly5Zpv3xxx9aw4YNNV9fX61q1araRx99pH377bdZui/IrQsHfZ3Z3TJf/i/llm4ipPsAWW+NGjW0Z599VtuxY4fNfHLp/+233666Xahbt662YMECtS8L04VD5u4K9O2YOHFirvv24MGDWocOHVT3BGFhYarLiX/++Sfbriykm4A6deqosksXG7Kfe/TooaZlNmPGDK1Zs2aqi4GgoCDVBcTIkSO1c+fO3XQbszueuX1urLsrSElJ0UaMGKE1atRIrTcgIEA9njZtms174uPjtSeffFJ1v5H5eF64cEHr27ev2h/e3t6q7Nl16yFllGXIeuS4y/HeuHGjWp51lwpyfKUc2cnr/s9pGdl9JnLaT0R5YZA/zgvpiIgoJ1IFKpk7tiO60aP/I488ojo/lawfUVHDNllERE4m7Y+s+yLThx2SYWSkh/RbUeahb6Q9mFT/SrWfVB0TFUVsk0VE5GTSZkiunpSLHqQRuVxtJ8O3SLcVcnHArejll19WgZYMXyON6qWLiE2bNqn2a668spKoMFhdSETkZHIlnjQKlwbgcsWkXJ0n/ZFJx7R6Nxa3GhmEWRrTS8P35ORk1RGp9Oou4wkSFVUMsoiIiIgcgG2yiIiIiByAQRYRERGRA7DhuxNJD8Yykr10wJfX8eiIiIjItaRllXTOKxeqZB4O7GYYZDmRBFgywC4REREVPadPn1ajIOQVgywn0oeQkIMkfb8QERGR+7t27ZpKkujn8bxikOVEehWhBFgMsoiIiIqW/Db1YcN3IiIiIgdgkEVERETkAAyyiIiIiByAbbLckAyMKgPIEhG5kpeXFzw8PFxdDKIii0GWm/XDERUVhZiYGFcXhYhICQ0NVQNXs28/ovxjkOVG9ACrTJky8Pf355caEbn0R19iYiIuXryonpcrV87VRSIqchhkuVEVoR5glSpVytXFISKCn5+fupdAS76bWHVIlD9s+O4m9DZYksEiInIX+ncS24kS5R+DLDfDKkIicif8TiIqOAZZRERERA7AIItc6r///lO/lPfs2ZPn98yaNUtd8eTqchRFq1evxu23367aABZ19957L4YOHVro5dwqxz6z5cuXo3HjxjCZTK4uClGxxSCLCk0GvO7Xrx/Kly8Pb29vVKlSBUOGDEF0dHSu75UBN8+fP4/69evneX09e/bEkSNHUFRP6q40cuRIvPXWW5YGzBKwSoAhgVdm8+fPV69VrVoVRdHNgnHZrt9++y3fn8HiFJA98MADqh+sn376ydVFISq2GGRRoRw/fhx33HEH/v33X8yePRtHjx7Fl19+qTImrVq1wpUrV3J8b2pqqjrZSx88np6e+briSa50ovz5+++/cezYMfTo0cNmekBAgLp6bPPmzTbTv/nmG1SuXBnFXUE+g87qQiE9Pd2h63j22Wfx+eefO3QdRC6XmuiyVTPIokIZPHiwyl79+eefaNu2rTopd+rUCatWrcLZs2fx5ptvWuaVjMj//d//4ZlnnkFwcDCef/75bDMDf/zxB2rVqgVfX1+0a9cO3333nZpH76Q1c4Zi3Lhxqtrjhx9+UOsICQnBE088gbi4OJuqkbvvvlu9T7rI6NKliwo4CkPW9d5776ntCQwMVBk8KfulS5fQtWtXNa1hw4bYsWOH5T2S3evVqxcqVKigrtpq0KCBCk6tSbl79+6tgh/pm+izzz7LkkVLSUnBa6+9ppYj87Vs2RLr1q27aXnnzJmD+++/X+1XaxJcPPnkk/j2228t086cOaOWJ9OtyT6TbQsPD1fb17x5c3WsM++XDz74QGU3g4KC1GdixowZltdludbHU8jxl2nyecjrfrKXzJ/Bq1evqv1funRpFdDLZ3HmzJnqtWrVqqn7Jk2aqPfIcRFS5fbuu++iYsWK8PHxUZ9H+cxZ27Rpk5ou+19+mEgmzXq9+n5ZtmwZmjVrppajB8Z52ef5/SyKhx56SE0r7P8Ckdv6exLwQTng+M2/Hx2FQZY7dwSYmu6Sm6w7LyRLtWLFCrz44ouW/nR0khmQE9XcuXNtlvfxxx+jUaNG2L17N95+++0syzxx4gQeffRRdOvWDf/88w9eeOEFm0AtJ3KSkJPW4sWL1W39+vX48MMPLa8nJCRg+PDh6oQiWTaj0YhHHnmk0O1RJABq3bq12p7OnTvj6aefVie6p556Crt27UKNGjXUc30fJCcnqxPokiVLsH//fhVoynu2bdtmWaaUc+PGjeokuXLlSvz1119qWdZeeukllXmSwGnv3r147LHHVPWPZBRzIsuRk3t2JCCaN2+e6nxSD2RleXJitxYfH48HH3xQ7UPZZplHTtSnTp2yme+TTz5R65J55PMxaNAgREZG5nm/5mU/OYp8Lg8ePKiCnUOHDmH69OkICwtTr+nrlyBHqhgXLFignk+ePFlts3y+5XhERETg4YcfthyPa9euqf0kwaIcS/mx8frrr2e7/lGjRqnPrqxbAqO87vP8fhaFBMByjOWzQVQsRe0131885JLVu1d+nCyS0jJQd8wKl6z74LsR8PfO/aMhJxD5ws6uPY+Q6ZIVkF/TevXefffdh1dffdUyj5650H311VeoXbs2Jk6cqJ7LYznJvv/++zctiwRLEhhI5kTICUZOSvr7MleRSdZGMhVyMs1Pe7DM5OQngaAYM2aMOiFLpkGCHiEnUqk2vXDhggo8JTMjGSjdyy+/rAJVCXBatGihsliSufv555/Rvn17NY9kUaS9m05OrjJN7vXpskzJnMh0ySJl5+TJkzbLsSaZmerVq+OXX35R+0725aeffqqqg61JgCw3nQQLCxcuVAGhBH7W+0WCK30fSACwdu1adTzzIrf9lFexsbEqi5Mfsl9lf+gBqXWbNPnMCMmGyvHUSXAl2ykZVPHRRx+p7Z00aRKmTp2qjqdkqb7++muVyapbt67K9A4YMCDL+iUjJhlHXcmSJfO8z/PzWdTJZ0I+G0TFkqb/qHBNVyQMsqjQ8pr5EjllUnSS7ZATg7W8nFTlRKgHWEKq2fThQPSAUE48W7duxeXLly0ZLDmhFibIkkyDTs/6SLYi8zQpi5zY5Ko+CYIkWJCTrLRLk6o/vcNHCWqk00frbZbqT+vgZN++fWo5t912m01ZZDk3Gy0gKSkpS1Vh5myWBGmS3ZDMn5y0p0yZYjOPZFWkelYyTJLJkTZDstzMWRXr/SLBhWy79fHITW77Ka/kM5E5CyikCjAnknWToFze17FjR5VVveuuu3KcX7JU586dU1kka/JcsrH651r2ifX+z+lznfl/pCD7PC+fRZ1kofUMJlHxo5nvDK6puGOQ5ab8vDxURslV686LmjVrqhOoVGtI1VtmMr1EiRKWX/9C2g85glwlZU3KZV0VKNUr0k5FMgnyy11ek+BKTt72Wq/eaWN20/SySIZOqpYkwyEnQNkf0tYqP+WQk6401t65c2eWYU5ulrWRKi/JLOZEqnfl6kM5oUs2K7uG4JJdkipMydzI8ZcTtFTvZi7/zY6HVNVmDs4z9yZuj/2kr0vKmR/SplAyO0uXLlXbKhlFaXso2+wMmf9HCrLP8/JZtK72t/4fJSpWDiw03x/6A2j5vNNXzyDLTckXYl6q7FxJsiZSrTFt2jQMGzbMpl2WDHYtl4ZLG5D89BgtGRs5uVnbvn17ocopjaglkyABVps2bdQ0aVDsCtLWShoiSzsZ/YQn3VFI9ZGQKjs5Mco261f2SZWXzHPPPfeo51KVJZkeyUjo25MX8j6pHs2JVEtJOyLJHskVojmVX65I04NqCfgyV/nmRj+hS1ZGgnCRuUuE3PaTo0kZ+/Tpo26yj0eMGKGCHLnIQ1j3MyYXcUjgLmWWiz+st0HPVsnn+scff1TZOGnQnp/PtT32+c3avkl7RvlsEBVrV11TJc6G71QoUp0kJw5p6LthwwbVZ5a0DZLgS9rV5NaWKjNpU3L48GHVfkROqnLCl/ZBhRneQ07kEhDKFW7SxcSaNWtU43JXkGoqyUrIlWaS6ZPtlTYy1tVbcmKXk7q06Tlw4AD69++vMjL69ks1oWSdJICVhtdysYA0yB4/fryqUsqJHKPcgkvZ11KdWqdOnRzLL+uUoEiqwuTqw/xePCDZGOmbSjJmUo0rZZZG4/nZT44k1cq///67+qzI/pcLKfR2h9K2UH5MyGdcyiMBsJDjJe2w5EIPCeil8brsI+kvTuj7SRrwy/ZI+zI9M5bb59oe+zwnW7ZsUUGftNUiIvtjkEWFIicAuWJPMjCPP/64uoJJTiTS9YJc/SbZkfyQS+Sl8bWcVKSNiTTe1a8u1DMA+SUBilyFJ9VrUkUoWTe9Yb2zSUegTZs2VQGPXP4vbWOkzY81aXAuJz3pZqJDhw6qbY+c5K3b80jbKQmy5CICyZLIMqyzX9mRwEyChptd5ScBxM3adUnZJGiVNkpSBSvbIduTH5Kpk+4YJJiWYyzBiXQ/kN/95CiSrRo9erQqm2QPpUpWPj9CqlClXym5QEOyV5JtE6+88ooK3OV4SPWmBGF6VyR6tmvRokUqUJJuHOQzLcGcuFk7OXvt85zIcZDPBQemJ3IMg5afVstUKNJAVhoxy69f+dLNnLaXjIQEGbl96d5qJBsm1VeSJbsVSSN0yQpKtkeyWoUhGRf5HEqQQK4l1el9+/ZV3weZu0BxBslYSoAuP5L0/r+yw+8mKtLGhZjva7QHnjZ3uWLv8/fNuHejH7olSRsvucJQMirSHkWyTtaXqhd30s+RZHmkPY/8Q8sl/ULPmhSGZFBk/0p1k94AnZzj+++/VxlfCZil2k+qxCX764oAS0i7Lvks3CzAIirymj0L7JwFVL7TJatnkEVuR9rpSPWRXPUk1V9SBSPVN7cSaa8j1XpSdSWdckpnkXqHmIUhPd6/8cYbdikj5Y9cDCJVhHIvXYxI/1X5bbNoT9JVRG5dqhAVfQbznYsq7Vhd6ESsLiSioobfTVSk/dIf2P8LcPcwoMM4p1cXsr6AiIiIiqek630Dhtl23uwsDLKIiIiomDO4ZK0MsoiIiKh40kwuHVaHQRYREREVT8fXmu+lXZYLMMgiIiKi4u3iYZeslkEWERERkQMwyKJb0rp169SYcTExMZYx+6QPKUeSQX6dNTSMK8lQND///DOKMhnKZ+jQoXZfbtWqVTFp0qQCv1+G65Fheew1diERORaDLCp04CDByocffmgz/bfffivwgM6u0LNnTzUgtTsFfkWRjNcnAyc/8cQTduuVXIYSkj6apGd0GRtz7NixSE1NhbuQMspxk3EJcwvWZHxJGduzoAHZAw88oMZ+lCF5iCgfQirCFRhkUaFJB4UyyO/Vq9f7I7ETZ55I5QRepkwZp62vuJLBk2U8PnsN2SPDC0nWRsZalMGtP/vsMzWOZVHttb506dKFHoxZftjIfiaiPGg9xHxfwT6DqucXgywqtA4dOqBs2bIYP378Tef79ddfUa9ePfj4+Khf6TLgsTWZ9n//93945plnVI+68otfr8ZbvHixGsxWTlCPPvooEhMT8d1336n3lChRAq+88goyMjIsy/rhhx/UkCFBQUGqbE8++SQuXryYY9kyVxfKciU7kfmmk8GqZdw5eU/JkiXVuIKS0dBJWYYPH65elzEYR44cifwOruDIbZeMU61atVSA3K5dO7W8zFm0v//+G23atFEBaKVKldR6ZLDqnFy6dAlr1qzBQw89ZDNdlvnCCy8gPDxcra9+/fpqm6QHZVn2smXLbOZfuHChKrtsp2RuZs6ciY4dO6px/x5++GG89tprWLDg5gO95rROER0djV69eqkxBGWfNmjQALNnz77p8lJSUtRYg7If5PNbs2ZNfPPNN8gv6+yUfB7GjRunho6SZZYvX17tYz0DdvLkSQwbNizLZ0/2rwzqfOzYsXyvn+iWYzDaduXgZAyy3F1qQs63tOR8zJuUt3kLwMPDAx988AG++OILnDlzJtt5du7cqYISqUbat2+fOrm8/fbbKpDIPGZfo0aN1CDJ8rqQk638cp8zZ45qkyLVao888giWLl2qbhJUSKbjl19uXKKblpamAjYZiFeqLiUAkgxAXkm1zvnz59VNtunOO+9UAYe+7IiICBUIyJiCMoh1YGCgCgj07JsEkLJt3377rQpWZBxGCR7yyxHbLkOkSLAm7cNkHglGZOBoa3ICl+3p0aMH9u7di7lz56rtuNlA3fK6BC233367ZZpkoTp16qT20Y8//oiDBw+qqmX5zEgg3aVLlyztt6QqTMqWU8ZHhrWQwDYnN1unPkyMjAe5ZMkS7N+/XwXzTz/9NLZt25bjMiXwl0BMjsWhQ4fUPpdjXhjyo0Myc7IsGa9TjpUEfEKCyIoVK6rBwfXPoU6CMgke5bNHRLnISDPfm278EHUqGbuQnCM2NlZSGeo+s6SkJO3gwYPq3sbY4JxvPz5qO+97ZXOe99sHbef9qFr28+VTnz59tK5du6rHd955p9avXz/1eOHChWpbdU8++aR2//3327x3xIgRWt26dS3Pq1SponXr1s1mnpkzZ6rlHD161DLthRde0Pz9/bW4uDjLtIiICDU9J9u3b1fL0d+zdu1a9fzq1auW9YSEhGT73ldeeUWV7eLFi+r5Dz/8oNWuXVszmUyWeVJSUjQ/Pz9txYoV6nm5cuW0CRMmWF5PS0vTKlasaNlX2cmuTI7Y9tdff12rX7++zTxvvvmmzbr79++vPf/88zbz/PXXX5rRaMz6Gb3us88+06pXr24zTfaHvCcyMjLb98jnJDAwUEtISFDP5X/D19dXW7ZsWbbz//vvv1pwcLA2Y8aMHLc3t3Vmp3Pnztqrr75qed62bVttyJAh6rEsR/bNypUrs33viRMn1Oty/AMCAmxuUg59OUI+R7KfxCeffKLddtttWmpqarbLtZ43syZNmmjjxo3TnCHH7yaiomD63eZz2/4FDjt/3wwzWWQ30i5Lqp3kl35mMq1169Y20+S5/IK3ruqSaq7MJKMhDZ518iteql2sMwkyzbpKTDJnUq0iv/ol49S2bVs1/dSpU/naphkzZqhqIalek/Y0QrI/R48eVcuVMshNMiuSIZEMkGRaJPPQsmVLy3I8PT2z3bbcOGLbIyMj0bx5c5v1tGjRwua5bKNk4vTtk5tk7yRLJJmw7CQlJWUZQFgag0tG5rbbsh837MEHH1QNuWX/6tkdyXBJFXRmZ8+eVdm1xx57DAMGDMhxn+W2Tvm8SaZPskZy3GTbVqxYkeNnQ5YnWTB9P+ZEsn0yr/XtZsdctkP2mVSDyvZIpjM9PR15IdWskuUkolx4eJnvPV0zuLmnS9ZKeffGuZxfM5irPyxGHL3JvJni6aH74IhL9+VEPHr06HxVzVkLCAjIMk1OwtakfUp20/TL2qXdkJRDblL1JMGRnEDleX4a069duxYvv/yyqiZq2LChZXp8fLyqbsruCi89ELMXV227bKNUI+pthKxJ8JadsLCwLBc/SDBwM97e3qrqUqoMpSpZ7uVKTwlKrZ07d061HbvrrrtU4Hszua1z4sSJmDx5smobJYGWfObkCsCc9k9uy9NJey1pq5XX98r8EvCuWrUKK1euxIsvvqjKtn79+izHODOpfrb3Z42oWNL0trCuudqdQZa78w5w/bz5IG1fpB8faahtTdrpSBsZa/Jcsg16Wxl7kSvSpHGzlEVOZEIaCueHZKrk5C9XsXXv3t3mtaZNm6qshVyNKFmX7JQrVw5bt25VgaeQDIVkmOS9jpSXbZdjI+25MrdBsybllLZMmYOGm2nSpAmioqJUoCUN8oUEp9KmTbrHyCmz1Lt3b9x///3q6kFpOP/ee+9lyWBJgCWBrTSCz+3KxdzWKZ87uVDhqaeeUs8lQJV569atm+3yJBCTeST4yS7DVhgShEnWUW6DBw9GnTp1VJtF2f8SgFpneXV6xlT2NxHl4twu8/3eOUDtB+BsrC4ku5ITkpw0M19i/uqrr2L16tWqmkZOaFKtOGXKFHWlmL1JpkVOUNIQ//jx46oqStabV1KFIyc9OYlJo2gJHPSbkO2TrI2cqKXxsVSfSYN0yfroDf+HDBmiAh1pzCyBj2QpnNH/VV62XTJUUia5Wk6Oxbx58ywXIOhXsclrmzZtUg3dpdpLqnV///33mzZ8l/0l+8U6mJYqNgk0pQG9ZGtkX8nVhNKIXyevy1WQsl+lPyzralYJsORKO9kuuShCrmC0Phb6PBKc6A3Xc1unXFUp02X7pBpb9of07ZUTqZ7t06cP+vXrp46nfrxlvxWG7HOpipbG93KspJG+BF1VqlSxrHfDhg1q+y5fvmx535YtW9TViK1atSrU+oluKWd2umS1DLLI7uSKqMw9UssvczkpyVVycjn9mDFj1HwFrVa8GalGkRPY/PnzVXZCgh05QeeVnHAlCJGgUC6rl6yUftPbScnJT078kuWSLJ10mCkZBj2zJUGlXLEmJ2c5GUrbKLkq0NHysu0SyMjViHIFm2R9pk+fbrm6UE7eQqZL5kaCMLmqUgIoOWayP3IiGUnpIytzNaq0s5I2YNJtgpRJurOwztBIYCevSTswCbSsSTAkWUU5FtLOKvOx0K+mlGo36zZKN1vnW2+9pT6PUoUqAZwEeLn1xC/7SDKbEixLQCdtqG7WnUVeSPccX3/9tWqbKPtbqg0XLVqkuvwQ8v8hV4ZKmzzrqkGpvpb9VNj+tojI8QzS+t0J6yFA9QsUEhKiGkZnrmaSE7T8QpYTYObGw0SO9v7776tOPqX/r8KQDJP0hbZr1y5LRobsRzJaUt0rVcDyXeEM/G6iIm1ciPk+pDIwbJ9Dzt83wzZZRLegadOmqUyPZE2kek8aXN+sKjCvJCskVWDS2J5Blv1JZkuOnbMCLKJiIyDMJatlkEV0C5I2VtLAXK5Sk2pPqd6Uq0Lt4VYYBNtVpEuIgnQFQnTLaj8WWP0OEJ79hS2OxiCL6BYkPY3LjYioWDNc77rBRS2j2PCdiIiIiimD+Y5BFgleh0BE7oTfSVSkbb8+kHs9x1/dnR0GWW5C7+GZQ2UQkTvRv5Ny64WeyC15epvvfQJds3qXrJWy7WNI+s3Rx6CTPnD0jiGJiFyRwZIAS76T5LvJ3iMzEDmFZsp+aDknYZDlRuTyd2E92C8RkStJgKV/NxEVOVeOm+/3/ARUvtPpq2eQ5UYkcyU9WcuYeNKLNRGRK0kVITNYVCwcX+ea9WpuYvz48dK6UhsyZIhlWlJSkvbiiy9qJUuW1AICArTu3btrUVFRNu87efKk9uCDD2p+fn5a6dKltddee01LS0uzmWft2rVakyZNNG9vb61GjRrazJkzs6x/ypQpWpUqVTQfHx+tRYsW2tatW21ez0tZchMbG6u2Ue6JiIjIwcYGm2+f1i/UYgp6/naLhu/bt2/HV199pcbvsjZs2DA1lpeMwybjqJ07d06NFaeTscg6d+6M1NRUNdirDDos47bJGGs6GQ5C5mnXrp0a6Hbo0KF47rnnsGLFCss8c+fOxfDhwzF27Fg1HEijRo3UuGbW1Xa5lYWIiIjIhuZicXFxWq1atbSVK1dqbdu2tWSyYmJiNC8vL23+/PmWeQ8dOqQiyc2bN6vnS5cu1YxGo01Gafr06VpwcLCWkpKino8cOVKrV6+ezTp79uypRUREWJ5L5mrw4MGW5xkZGVr58uVVdi2vZckLZrKIiIhckMma2urWzGQNHjxYZZo6dOhgM33nzp2qXZL19Dp16qghQDZv3qyey32DBg0QHh5umUcyUDKQ44EDByzzZF62zKMvQ7Jgsi7reYxGo3quz5OXshAREZGb6fyJ+b6ka8b7dGnD9zlz5qjqOakuzCwqKgre3t7qyhZrElDJa/o81gGW/rr+2s3mkUAsKSkJV69eVdWO2c1z+PDhPJclOykpKeqmk3USERGRk7io6wady9Z++vRpDBkyBD/99BN8fX1RHI0fPx4hISGWW6VKlVxdJCIioltwWB3TrRVkSRWcNCxv2rQpPD091U0alH/++efqsWSJpCovJibG5n0XLlyw9Nki9/I88+v6azebJzg4GH5+fggLC1OXKGc3j/UycitLdkaPHo3Y2FjLTQJLIiIicpI175nvWw7ELRVktW/fHvv27VNX/Om3O+64A71797Y8lj5aVq9ebXlPZGQkTp06hVatWqnnci/LsL4KcOXKlSqAqlu3rmUe62Xo8+jLkGrAZs2a2cxjMpnUc30eeT23smTHx8dHlcX6RkRERE6ij5wSUBq3VJusoKAg1K9f32ZaQEAASpUqZZnev39/1bVCyZIlVYDy8ssvq6DmzjvNvbZ27NhRBVNPP/00JkyYoNpHvfXWW6oxvQQ4YuDAgZgyZQpGjhyJfv36Yc2aNZg3bx6WLFliWa+so0+fPiqwa9GiBSZNmoSEhAT07dtXvS5VfbmVhYiIiNx1WB2DS1bv1j2+f/bZZ+pKvx49eqgG5HJV4LRp0yyvSzXf4sWLMWjQIBXwSJAmwdK7775rmadatWoqoJJ+riZPnoyKFSvif//7n1qWrmfPnrh06ZLqX0sCtcaNG2P58uU2jeFzKwsRERG5mcRo8/3uH4GI952+eoP04+D0td6i5OpCyYpJ+yxWHRIRETnYuBDzfUhlYNg+p5+/Xd5PFhEREVFxxCCLiIiIyAEYZBEREVHx5mm+GM7ZGGQRERFR8dTjG/N9UM59WjoSgywiIiIqngy36LA6RERERA5luEWH1SEiIiJyqD9eMd+3HwNXYJBFRERExVNakvk+pKJLVs8gi4iIiIopzaVtsxhkERERUfFkSr8xrI4LMMgiIiKi4m3XDy5ZLYMsIiIiIgdgkEVERETFj3a9PZYLMcgiIiKi4h1kGdnwnYiIiMg+JLDq/av5sU+Qa4rgkrUSEREROa3Hd7gEgywiIiIqngwcVoeIiIjIvtJTgPl9zY8f/hyuwCCLiIiIih9TBpAcY35cuo5LisAgi4iIiIoh7cZDDqtDREREZCfW7bB2s8d3IiIiIvsHWZumwBUYZBEREVHxo7HHdyIiIiL7c1G3DdYYZBEREVHxY3B9iOP6EhARERHZm18o8Nxq205JnYxBFhERERXzHt81l6yeQRYREREVUwbzHYfVISIiIrKThMvA3KfNjx+bCVdgkEVERETFT0YqcO0MYPAAKrVwSREYZBEREVHxo2kuv8qQQRYREREVP9r1dlimNGAXh9UhIiIishOrKwpXvwNXYJBFRERExY9mFWTx6kIiIiIiO7EOrNhPFhEREZGdGD2snjDIIiIiIrKP0MrASzvMj1ldSEREROSIHt/hEgyyiIiIqJiPXWhyyeoZZBEREVHxc/U/YE5v8+PHv3NJERhkERERUfGTlgRcOgT4lwJqtndJERhkERERUfGj6Q2xrlcZugCDLCIiIiqGNPNd4mVgz2yXlIBBFhERERU/mlVj90WvuKQIDLKIiIio+NE4rA4RERGR/XFYHSIiIiIHD6vDTBYRERGRnZRtALz27/UnzGQRERER2Y/B6NIqQwZZREREVEwZbjxkkEVERERkBxcPAbOfADy8gcdmwRUYZBEREVHxkxwLnNkGhFQE6j0CGJ0f8jDIIiIiouJH47A6RERERPand9tw5Riw/1cgIx3OxiCLiIiIiiHtxsNf+gEZqU4vAYMsIiIiKn60zB2Q8upCIiIiosLL3GWDC3p9Z5BFRERExY9BGryznywiIiIi+6p2D/DWxRvPmckiIiIismc2S8dMFhEREZF9cOxCIiIiIjs7uxP4uSfgEwJ0nQZ4+cPtg6xdu3Zh3759lue///47unXrhjfeeAOpqc7vg4KIiIgoi/hLwNGVQKnqQJPegJcv3D7IeuGFF3DkyBH1+Pjx43jiiSfg7++P+fPnY+TIkfla1vTp09GwYUMEBwerW6tWrbBs2TLL68nJyRg8eDBKlSqFwMBA9OjRAxcuXLBZxqlTp9C5c2dVhjJlymDEiBFIT7ft1XXdunVo2rQpfHx8ULNmTcyalXWgyKlTp6Jq1arw9fVFy5YtsW3bNpvX81IWIiIichda1ipDJ8v3miXAaty4sXosgdU999yDn3/+WQUuv/76a76WVbFiRXz44YfYuXMnduzYgfvuuw9du3bFgQMH1OvDhg3DokWL1HrWr1+Pc+fOoXv37pb3Z2RkqABLMmibNm3Cd999p8oxZswYyzwnTpxQ87Rr1w579uzB0KFD8dxzz2HFihWWeebOnYvhw4dj7NixKlPXqFEjRERE4OLFG1cl5FYWIiIiciOadqPaMHI5kJbsijLkT1BQkHbkyBH1uEOHDtqkSZPU45MnT2q+vr5aYZUoUUL73//+p8XExGheXl7a/PnzLa8dOnRI9pi2efNm9Xzp0qWa0WjUoqKiLPNMnz5dCw4O1lJSUtTzkSNHavXq1bNZR8+ePbWIiAjL8xYtWmiDBw+2PM/IyNDKly+vjR8/Xj3PS1nyIjY2Vr1H7omIiMiBDi7StLHBN26x5wq8qIKev/Odybrjjjvw3nvv4YcfflAZHckS6Rmj8PDwAgd7kpWaM2cOEhISVLWhZLfS0tLQoUMHyzx16tRB5cqVsXnzZvVc7hs0aGCzXslAXbt2zZINk3msl6HPoy9DsmCyLut5jEajeq7Pk5eyZCclJUWVxfpGREREzpD5asIicHXhpEmTVJXaSy+9hDfffFO1cRK//PIL7rrrrnwXQBrRSxsnaS81cOBALFy4EHXr1kVUVBS8vb0RGhpqM78EVPKakPvMgZ3+PLd5JOBJSkrC5cuXVYCX3TzWy8itLNkZP348QkJCLLdKlSrle/8QERFRAWTufNQFnZF65vcN0lDd+upC3cSJE+Hh4ZHvAtSuXVu1lYqNjVWBWp8+fVSGrDgYPXq0auulk8COgRYREZErxi7U3D/IyolclVcQkiHSs2HNmjXD9u3bMXnyZPTs2VNV5cXExNhkkOSKvrJly6rHcp/5KkD9ij/reTJfBSjP5WpGPz8/FRjKLbt5rJeRW1myI9k5uREREZGT1esG1I0B3gsHMlLcd1idEiVKoGTJknm6FZbJZFJtmSTg8vLywurVqy2vRUZGqi4bpM2WkHvJqllfBbhy5UoVQEmVoz6P9TL0efRlSJAn67KeR8ogz/V58lIWIiIicsNhdYx6LZubZrKkHZajqtM6deqkGpDHxcWpriCkTyvpXkHaMPXv319Vt0nwJoHTyy+/rIKaO++8U72/Y8eOKph6+umnMWHCBNU+6q233lL9WekZJGnnNWXKFNWHV79+/bBmzRrMmzcPS5YssZRD1iHVlNKov0WLFmp7pQF+37591et5KQsRERG5IYPRZdWF+e7CwZ769eunValSRfP29tZKly6ttW/fXvvzzz8tryclJWkvvvii6tbB399fe+SRR7Tz58/bLOO///7TOnXqpPn5+WlhYWHaq6++qqWlpdnMs3btWq1x48ZqPdWrV9dmzpyZpSxffPGFVrlyZTWPdOmwZcsWm9fzUpbcsAsHIiIiJ/lvk6bNfUbTPq2vaVtnaFpSTIEXVdDzt0H+5DcwO3bsGGbOnKnupf2U9LQuPbVLRqpevXqOiQaLAWn4LlkxaeQv2TAiIiJykL3zgAUDgOrtgGd+c8n5O99dOMiVf9I31datW7FgwQLEx8er6f/884/qMZ2IiIjI5fSG7tIuy0XyHWSNGjVKdUYqjcel0bhOhsTZsmWLvctHRERElH96Rd3p7cCJDUBqAtw+yJKr+R555JEs06XKUDr2JCIiInKbTFZqHPDdQ0DMafcPsqSfqPPnz2eZvnv3blSoUMFe5SIiIiK6tYbVeeKJJ/D666+r7hIMBoPqU2rjxo147bXX8MwzzzimlERERERFbFidfAdZH3zwgRocWYaHkUbv0k/VPffco8YtlD6qiIiIiNxvWB3nB1kF6sJBnD59WrXPkkCrSZMmqFWrlv1LV8ywCwciIiInyUgD0lOAz+oCybHAC38B5Rq6dxcOa9euVfeSyXrwwQfx+OOPWwKsr776Kr+LIyIiIrI/Dy/AJxDw8i861YUPPPAARowYgbS0NMs0uarwoYceUt07EBEREbndsDpFoeG7ZLIWLlyI5s2b4+DBg2oMwPr166tU2p49exxTSiIiIqL8OL4e+O1FwDcUuP9dIKg83D7IkgbuEkxJYNW0aVPVZ9awYcPUwM5VqlRxTCmJiIiI8uPyEWDPT0BYLaD1ECAoHG4fZIkjR45gx44dqFixIjw9PREZGYnExET7l46IiIjoVhlW58MPP0SrVq1w//33Y//+/di2bZvqiLRhw4bYvHmzY0pJREREVJAg6+Ih4MwOICUObh9kTZ48Gb/99hu++OIL+Pr6qmpDCbS6d++Oe++91zGlJCIiIsoPvYeqS4eB/7UHLhyAs3nm9w3SN1ZYWJjNNC8vL0ycOBFdunSxZ9mIiIiI7NTjexG4ujBzgGWtbdu2hS0PERERkR24vsf3PGWypCpw1qxZqpdTeXwzCxYssFfZiIiIiAomS1CluWeQJV3Jy2DQQgIt/TERERGRW2o+AGj0JPBVGyDuvPtmsmbOnGl5LBktIiIiIrfm7W++SWekKshy4zZZJpMJH330EVq3bq16e5chdJKSkhxbOiIiIqLiPqzO+++/jzfeeAOBgYGoUKGC6sph8ODBji0dERERUUH8uwpY8hrgGwLcOxoIreK+Qdb333+PadOmYcWKFaqfrEWLFuGnn35SGS4iIiIit3JuN7D9a/OwOveOAkpWc98g69SpU3jwwQctzzt06KAawJ87d85RZSMiIiIq5LA6BRpB0C7yvOb09HTVw3vmTkjT0tIcUS4iIiKiQrjeBivmFHDhoEuG1clzj++apuHZZ5+Fj4+PZVpycjIGDhyIgIAAyzT2k0VERERuk8k6thqYvhp4ch5wW4R7Bll9+vTJMu2pp56yd3mIiIiICi9zlw0u6MIhz0GWdV9ZRERERO5Ny/TU+Rfqua41GBEREVExHlaHQRYREREVP3e9DAz5ByhV0/zcnXt8JyIiIioy/EoAJaoC/mHm56wuJCIiIrqFhtVp2rQprl69qh6/++67SExMdHS5iIiIiAruyArgz7cB32DgrleAkjXglkHWoUOHkJCQoB6/8847iI+Pd3S5iIiIiAruxAZg0+dA6dpAx/8DytaHW3bh0LhxY/Tt2xd333236pT0448/VgNFZ2fMmDH2LiMRERFR/lgauhvgKnkKsmbNmoWxY8di8eLFarzCZcuWwdMz61vlNQZZRERE5HrXg6yEy8CVE0BAacAn+wSRoxg0SU3lg9FoRFRUFMqUKeO4UhVT165dQ0hICGJjYxEcHOzq4hARERVfy14Htn5543n3r4GGjzv1/J3nHt91JpPzL4EkIiIiypfMXTa487A61o4dO4ZJkyapBvGibt26GDJkCGrUcH7LfSIiIqLcxy4sAv1krVixQgVV27ZtQ8OGDdVt69atqFevHlauXOmYUhIREREVsWF18t0mq0mTJoiIiMCHH35oM33UqFH4888/sWvXLnuXsdhgmywiIiInuXYeSLoK/DYIOL8H6DoVaPKUU8/f+c5kSRVh//79s0zv168fDh48mN/FEREREdlfcDkgvC4QGF50xi4sXbo09uzZk2W6TOMVh0REROSWw+poJvdv+D5gwAA8//zzOH78OO666y41bePGjfjoo48wfPhwR5SRiIiIKH8OLwWi9gI+QUDz58w9v7t7kPX2228jKCgIn3zyCUaPHq2mlS9fHuPGjcMrr7ziiDISERER5U/kUmD3D0D7MUCbV+EK+Q6ypFf3YcOGqVtcXJyaJkEXERERkdvQisiwOjlhcEVERETu6XqQlZoAxF8CvAMAb3/3bvhORERE5Pa06w3d//oY+LgmsPtHpxeBQRYREREVP5rrOyNlkEVERES3wLA6mnsHWWlpaWjfvj3+/fdfx5WIiIiIyO4DRLv52IVeXl7Yu3ev40pDREREZA/3vQk8twaods/1CW6eyRJPPfUUvvnmG8eUhoiIiMgeSlYHKjYDgsoVnR7f09PT8e2332LVqlVo1qwZAgICbF7/9NNP7Vk+IiIiIjsMq6O5f5C1f/9+NG3aVD0+cuRIlo5KiYiIiFzu8BIg+hjgHQg07g2Uud39g6y1a9c6piRERERE9vLPbODQIqDzJ+axC12gwF04HD16FCtWrEBSUpJ6rrkgDUdERETkrsPq5DvIio6OVt043HbbbXjwwQdx/vx5Nb1///549VXXDMBIRERElG2QZcowD62Tngq3D7JkYGjpyuHUqVPw978xBlDPnj2xfPlye5ePiIiIqACuB1nLRgIflAc2Tobbt8n6888/VTVhxYoVbabXqlULJ0+etGfZiIiIiApG77JBri7UMopGP1kJCQk2GSzdlStX4OPjY69yERERERW+utDoWTSG1RFt2rTB999/b9Ntg8lkwoQJE9CuXTt7l4+IiIio4Jkso4ftc3euLpRgShq+79ixA6mpqRg5ciQOHDigMlkbN250TCmJiIiI8qPDOOCul4HtX5u7cigK1YX169dXnZDefffd6Nq1q6o+7N69O3bv3o0aNWrka1njx49H8+bNERQUhDJlyqBbt26IjIy0mSc5ORmDBw9GqVKlEBgYiB49euDChQs280gj/M6dO6tqTFnOiBEjVM/01tatW6c6UZUqzZo1a2LWrFlZyjN16lRUrVoVvr6+aNmyJbZt25bvshAREZEbKFsfqN7WpcPqFKifrJCQELz55puYN28eli5divfeew/lyl3fiHxYv369Clq2bNmClStXIi0tDR07dlSBm/XVjIsWLcL8+fPV/OfOnVNBnS4jI0MFWJJV27RpE7777jsVQI0ZM8Yyz4kTJ9Q8Up25Z88eDB06FM8995xqwK+bO3cuhg8fjrFjx2LXrl1o1KgRIiIicPHixTyXhYiIiNyMwXXD6kgnovl25coVbeLEiVq/fv3U7eOPP9aio6O1wrp48aLsAW39+vXqeUxMjObl5aXNnz/fMs+hQ4fUPJs3b1bPly5dqhmNRi0qKsoyz/Tp07Xg4GAtJSVFPR85cqRWr149m3X17NlTi4iIsDxv0aKFNnjwYMvzjIwMrXz58tr48ePzXJbcxMbGqvnlnoiIiBzo0GJN2zpD01a9o2lzn9G0vTfO3/lV0PN3vjNZGzZsUFVqn3/+Oa5evapu8rhatWrqtcKIjY1V9yVLllT3O3fuVNmtDh06WOapU6cOKleujM2bN6vnct+gQQOEh4db5pEM1LVr11RbMX0e62Xo8+jLkCyYrMt6HqPRqJ7r8+SlLJmlpKSocljfiIiIyAm2fgksfQ0oUxd4/DugwaNwtnwHWVK9Jx2PShXcggUL1O348eN44okn1GsFJVcoSjVe69atVbsvERUVBW9vb4SGhtrMKwGVvKbPYx1g6a/rr91sHgl6ZFigy5cvq2rH7OaxXkZuZcmuzZlUreq3SpUqFWjfEBERUT7p1YOGIjSsjoxZKMPneHhcvyQSUI+lPZO8VlASoO3fvx9z5sxBcTF69GiVndNvp0+fdnWRiIiIbr2xCzVNsjnuH2TJFXqHDh3KMl2mSWPxgnjppZewePFirF271qYn+bJly6qqvJiYGJv55Yo+eU2fJ/MVfvrz3OYJDg6Gn58fwsLCVKCY3TzWy8itLJnJlYyyDusbEREROYF+NeGqccA7ocDKt+GWQdbevXstt1deeQVDhgzBxx9/jL///lvd5LFceSe3/NA0TQVYCxcuxJo1a1S7LmvNmjVT4ySuXr3aMk26eJAuG1q1aqWey/2+fftsrgKUKxUloKlbt65lHutl6PPoy5BqQFmX9TxSfSnP9XnyUhYiIiJyF5ptZ6QuKUIeGAwGdQWf3N/sJvPkx6BBg7SQkBBt3bp12vnz5y23xMREyzwDBw7UKleurK1Zs0bbsWOH1qpVK3XTpaena/Xr19c6duyo7dmzR1u+fLlWunRpbfTo0ZZ5jh8/rvn7+2sjRoxQVwROnTpV8/DwUPPq5syZo/n4+GizZs3SDh48qD3//PNaaGiozVWLuZUlN7y6kIiIyEn+d7+mjQ3WtM+bme+XjSrwogp6/s5Tj+/SyN0Rpk+fru7vvfdem+kzZ87Es88+qx5/9tln6ko/6fhTrtaTqwKnTZtmmVeq+aSqcdCgQSqjFBAQgD59+uDdd9+1zCMZsiVLlqhM2+TJk1WV5P/+9z+1LJ005r906ZLqX0sasjdu3BjLly+3aQyfW1mIiIjI3cYu9LB97kQGibScvtZblFzNKFcZSiN4ts8iIiJyoFNbgKSrwOElwO4fgBYvAA9OcOr5O99jFwrp6VzaYkk7KGm7ZE3abBERERG5VOU7zfdnd12f4PycUr6DLBmy5oUXXlCNxWUMP4NV/xPymEEWERERuQ09TnHB2IX5DrLefvtt1W5J+oCS9klEREREbidymbm60MsfqNURKF3H/YOsxMRE1bs7AywiIiJyW2s/AKL2Ar1/Be4e6pIi5DtS6t+/P+bPn++Y0hARERHZhT6sDlwm35ksGY+vS5cuqnsDGZhZOui09umnn9qzfERERESFGLvQWLSCrBUrVqB27drqeeaG70RERERuE2RtmgLMfhJo3Avo8pl7B1mffPIJvv32W0tnoURERERuRzPduE9PAtJTnV6EfOfQZNDj1q1bO6Y0RERERA4Zu1Bz/yBLBof+4osvHFMaIiIiIntmsgweRaefrG3btmHNmjVqvMB69eplafi+YMECe5aPiIiIKP8ixgMpscD5f4B/V7hk7MJ8B1mhoaHo3r27Y0pDREREZA+1Opjvr50vOpmsmTNnOqYkRERERPZm6fmgCGSyiIiIiNzevyuB1ATzsDpV2wBh5q6n3DrIqlat2k37wzp+/Hhhy0RERERUOEteBWJOAv1XAXf0hSvkO8gaOtR2/J+0tDTs3r1b9QA/YsQIe5aNiIiIqICKYI/v0oVDdqZOnYodO3bYo0xEREREdhpWBy5jt/CuU6dO+PXXX+21OCIiIqLCB1n/zAEmVAcWDkKRDbJ++eUXlCxZ0l6LIyIiIio4vcuGjFQgMRpIuQa3ry5s0qSJTcN3TdMQFRWFS5cuYdq0afYuHxEREVEB6NWF+rA6cP8gq1u3bjbPjUYjSpcujXvvvRd16tSxZ9mIiIiICpfJ0scuLAqdkY4dO9YxJSEiIiKyl4gPgLQkIOlK0QmyiIiIiNxeg0fN97t+MN+789iFUi14s05Ihbyenp5uj3IRERERFZ4eu7hzJmvhwoU5vrZ582Z8/vnnMJmcvwFEREREWRxbA2SkA15+QPkmQKkacNsgq2vXrlmmRUZGYtSoUVi0aBF69+6Nd999197lIyIiIsq/+X2B5Bhg8Hbg+XVwhQL1k3Xu3DkMGDAADRo0UNWDe/bswXfffYcqVarYv4REREREBe7x3XXD6uRrzbGxsXj99ddRs2ZNHDhwAKtXr1ZZrPr16zuuhERERET5pgdZBvcPsiZMmIDq1atj8eLFmD17NjZt2oQ2bdo4tnREREREBaE3dD+yHPisPvBLP7htmyxpe+Xn56eyWFI1KLfsLFiwwJ7lIyIiIip4dWF6MhB7GihRFW4bZD3zzDO5duFARERE5FaZLIPR/fvJmjVrlmNLQkRERGQ314Mqo6f795NFREREVKSG1TFlAN4B1ye4cSaLiIiIqMho3t98f2iRy6oLXdd5BBEREZHDFYFhdYiIiIiKjP/+Nt97+QKl6wAlnN9hOoMsIiIiKn5mdTbfv3oEGLzVJUVgdSEREREVL5pV+6uiMqwOERERkdvTGGQREREROYBVkHV6KzClBTD3KTgb22QRERFR8aJZXUmYlghcjgQ8vZ1eDGayiIiIqPhWFxo9rk9zfjEYZBEREVExo914aNCDLPaTRURERFQ4Elh1eMccbHn5XZ/IYXWIiIiICsfDE7h7qPnxiQ3mew6rQ0RERGRPHFaHiIiIyD5MGcC5Peb4ytMXCKkMBJeDszHIIiIiouIlNR74333mx29dBIbtc0kxWF1IRERExYvGHt+JiIiI7M+m/dX1NlkuwCCLiIiIiq9Lh4Cv2gKzezl91WyTRURERMV4WJ1k4PweIOmK04vBTBYREREV/zZZmvOLwSCLiIiIihnt+r0BMLCfLCIiIiL78PIH2r5ufqwHWRxWh4iIiKiQfAKBdm+YH5//x2WZLFYXEhERUTFmMN+xupCIiIiokDLSgOijgMED8PAC/EsBfiXhbAyyiIiIqHiJOw9Mu9M8buFbF4CRx11SDFYXEhERUfHswsHg2jCHQRYREREVL5rJ5UPqCAZZREREVMxoN7pviDkNzHwQ+OmxWyvI2rBhAx566CGUL18eBoMBv/32m83rmqZhzJgxKFeuHPz8/NChQwf8+++/NvNcuXIFvXv3RnBwMEJDQ9G/f3/Ex8fbzLN37160adMGvr6+qFSpEiZMmJClLPPnz0edOnXUPA0aNMDSpUvzXRYiIiJys+rC9GTg5Ebg1NZbK8hKSEhAo0aNMHXq1Gxfl2Do888/x5dffomtW7ciICAAERERSE5OtswjAdaBAwewcuVKLF68WAVuzz//vOX1a9euoWPHjqhSpQp27tyJiRMnYty4cZgxY4Zlnk2bNqFXr14qQNu9eze6deumbvv3789XWYiIiMjNqgsNeqjjgnF1NDchRVm4cKHluclk0sqWLatNnDjRMi0mJkbz8fHRZs+erZ4fPHhQvW/79u2WeZYtW6YZDAbt7Nmz6vm0adO0EiVKaCkpKZZ5Xn/9da127dqW548//rjWuXNnm/K0bNlSe+GFF/JclryIjY1V5ZV7IiIicpCLkZo2NljTxlfWtMtHzY/fr1DgxRX0/O22bbJOnDiBqKgoVS2nCwkJQcuWLbF582b1XO6livCOO+6wzCPzG41GlW3S57nnnnvg7e1tmUcyUJGRkbh69aplHuv16PPo68lLWYiIiMhN+IUCd70MtHjeaoBodkZqIUGNCA8Pt5kuz/XX5L5MmTI2r3t6eqJkyZI281SrVi3LMvTXSpQooe5zW09uZclOSkqKullXXRIREZGDBZYBOr5nfnz1P5dVF7ptJqs4GD9+vMp46TdpdE9ERERO5MJMltsGWWXLllX3Fy5csJkuz/XX5P7ixYs2r6enp6srDq3nyW4Z1uvIaR7r13MrS3ZGjx6N2NhYy+306dP52gdERERUAOmpwNWTQOxZ89A6Xv7mm5O5bZAlVXwSwKxevdqmuk3aWrVq1Uo9l/uYmBh11aBuzZo1MJlMqr2UPo9ccZiWlmaZR65ErF27tqoq1OexXo8+j76evJQlOz4+PqprCesbEREROdilw8DkhsDX7YCQCsCb54HXT+CWCrKkP6s9e/aom97AXB6fOnVK9Zs1dOhQvPfee/jjjz+wb98+PPPMM6pPLeleQdx+++144IEHMGDAAGzbtg0bN27ESy+9hCeeeELNJ5588knV6F26Z5CuHubOnYvJkydj+PDhlnIMGTIEy5cvxyeffILDhw+rLh527NihliXyUhYiIiJyF5pbDKvj0i4c1q5dqy6JzHzr06ePpeuEt99+WwsPD1fdJbRv316LjIy0WUZ0dLTWq1cvLTAwUAsODtb69u2rxcXF2czzzz//aHfffbdaRoUKFbQPP/wwS1nmzZun3XbbbZq3t7dWr149bcmSJTav56UsuWEXDkRERE5wdpe524aP69hlcQU9fxvkj2vDvFuHVDFKA3hpn8WqQyIiIgc5u8tcVRhcERi0Efj1OfP0p35x6vnbbbtwICIiIir02IUZacDRlXAFt234TkRERFS4sQtlWB1D1ulOwiCLiIiIiu8A0Qajy4IsVhcSERFR8RIQBtzRH/AvZTtddUjqvPwSgywiIiIqXkpWA7p8an6cFGP1AqsLiYiIiOzDpk2Wc4fWYSaLiIiIit+wOsmxgIeneVgdHdtkERERERXC6a3Ad12AsNrA4K3AuFi4AqsLiYiIqJjJoQsHJ2OQRURERMWLZnKLsQsZZBEREVHxoultr673+D73aWDuU0BqolOLwTZZREREVHwzWZoGHPrD/PzhVAD+TisGM1lERERUTNtkIVObLPaTRURERFRwHFaHiIiIyAGCygKNegEhla6ns65jkEVERERUCGUbAI98mTWwcnKP76wuJCIiouLLwDZZRERERPaRkQ6kJgDpKdcnXA+0mMkiInIv3236D0Pm7EaGybm/gomogI4sBz4oD8zqYn7+xlngzSggMBzOxCCLiCgXU9Yexe97zuHguWuuLgoR5YnV1YXCOwDw8nP6EDsMsoiIcpGQkq7u46/fE1FR6YzU4NJiMMgiIroJk0lDYmqGepyUxiCLqMj1kyX+eBlY8AKQEA1nYpBFRHQTSWnmAEvowRYRuTlNb+B+PZO1dz6wdw6QGu/UYjDIIiK6iYTUG9mrxBQGWURFg2ZbXahntHh1IRGR+0iyyl4lWgVcRFQUqgsNtvdO7ieLPb4TEd1EglX2KoHVhURFQ3AFoG5XoEy9TJksBllERG7DOntlndUiIjdWpZX5ZqF3Rsoe34mI3IZ19ooN34mKKAN7fCcicjuJVn1jsU0WURGhabZZK7bJIiJyP9bZK2ayiIqIPT8Bvw8GanUEes8HXtppnu4b4tRiMMgiIroJ6+wVM1lERYSmZ6yuZ7ACSrmkGKwuJCK6CbbJIiqKNPMdh9UhIioqbbIYZBEVrbELjeb7VeOARUOB2LNOLQaDLCKiPGeyWF1IVCSrC/+ZA+ycCSRy7EIiIrfBhu9ERTmTZbg+gV04EBG5ecN3BllERXrsQrAzUiIitxxWh9WFREVESCWg5v1AuUYu7YyUXTgQEd2EdWCVnGZChkmDh9G1VywRUS5uizDfLPQgC07FTBYR0U1kHhQ6KY1VhkRFjsE1Pb4zyCIiuomkTFWErDIkKoIMrC4kInLrNlkiiY3fidzf1hnAqrFA/e5A16nAs0sBLQMIDHdqMRhkERHdRObMVeagi4jcUEYqkJYIpKean4dUcEkxWF1IRJSHNlleHubqhqQ0VhcSFbke312EQRYRUQ7SMkxITTd/WYcF+qh7ZrKIimA/WRsnAyveBK4cd2opGGQREeXAuvNRPchih6RERTCTtednYPMUjl1IROQu9EbunkYDQv29zNNYXUhU9MYuBIfVISJyKwnXG737e3uom5rG6kKiIpTJwvV7DqtDRORWEq8HVAE+nvD3Nl+MzS4ciIrIsDpV7gZK1bINsthPFhGRG2ey2Bkpkftr1NN801k6fGd1IRGRW/WRJVksPchiJouoCDLomSznrpZBFhFRDvQrCSXA8rteXcirC4mKIoP5jtWFRETu1yYrgNWFREXH358Bm6YATZ4C7n8HeGyWuRf4YOf2/M4gi4goH22yWF1IVASkJgCJl833omQ1lxSD1YVERDnQqwYDVJssVhcSFbl+sgyuDXOYySIiykFCyvVMls+NTFbmAaOJqAj0+L7reyDmNNDgUaB0bacVg0EWEVGeGr7rQRYzWURFbuzC3T8Cp7cC5Ro6NchidSERUR66cJDG7+ZpDLKIilwmCxxWh4jIrSRY2mR5wM+L1YVERW/swsz9ZHFYHSIit5BoaZN1ozNSZrKIioDgCkD5JkBIRfNzDqtDROSumSzb6kJN02DQ23oQkfu5c6D5prP8vzKTRUTkXm2yfG40fM8waUjNcO6vYSIqJD3IYnUhkWNI9oEor/adiUVkVJx6XDrQB/7X22RZ9wRPRG5m1w/AfxsBU+YfQteDLFMGkBLvtOIwyKJi78TlBDz59Rbc9eEaHLlgPmmSEx1aBHxQAdg7D0Wpf6xX5uxGWoaGB+qVRb3ywfD0MMLb0/yVeeyS876kiSiPpHf3ZSOBWQ8Cs3sCnzUANn1hfq3zJ8CAtcDB34AJ1YDT2+AMDLLyaerUqahatSp8fX3RsmVLbNvmnAN1Kzgbk4TYpDS7LnP2tlPoNHkDNh2LxvnYZLz08y4kpzknC/Hf5QSsOXzh1rsaLfYM8MfL5l+TImo/kBoPLBgApCXD3cUkpuKV2btVcF4uxBcf9mhgaX91722l1f2gn3bh9JVEF5eUiGxELgPSEoESVYHQKkDsKSA51vxaWC3A0xeIXGoew3D5KDgDG77nw9y5czF8+HB8+eWXKsCaNGkSIiIiEBkZiTJlyqCok5PLkn3nUTbYF+1ql4HRaNuw98K1ZKw9fFE9DvL1wp3VS6JUoE+Oy4tPScep6EREJ6SodizVwgJQNsQX3h5Gy0krJT1DVcl8/dcJLN57DkE+nhjV6XY80bySWr8ERCejE9UYcrIMLeESSh1dgEvl2iHGvwqiYpNxJTFNZRqaVSkBD4MBaSYTgn29MH3dMUxe/a9aT+uapRAZFQ/jxYP45pu9wG0PqEbNpRKPw9OUgguBt6uGzeHBvmo7d5+6igvXUlSAVL10IDo3KIcqpfxh0gBfL6O6nP/klUScuJQAL08jvIwG7D8bg/NnTyPOowSupaTj8PWqphL+Xni6VVV0uL0M6pYzZ0Ty5Np5wMMbCCiV/4MpVaNXTwChVQGjEUhPwZlj+/HFXk/sOHUVNUoHqv3VrUkFtc2IiwLizpuvxpH3yuPg8jkvPy3JXDbjjSo0JT0VmPsUcG43cOA34IX1QJtXgR3fAgkXgV3fAQ0fB05vB2q0Azy8gPN7gVObgcZPAj5BwH9/AxcPAU2fATx9bizX6GnelktHzOstVSNruS4eBpaNAKq0Bu4ZaZ7fmlQhXD4ClKoJeHiatzXlGuAbgisJqVh18AI+W3UE52OT4Gk0YmqXcIRe2glUvlO16fj48UZ4/MvN6tg+/eV6TK24ClXLBONai6EoZboK77CqN9aVkQYcWAiE1wfC6+b/GBZ3x9YAVe8B0pOBvXPNx6xMHVeXitxdciywbQZQuRVQ9e4b0+U7bO0H5sdB5YHtX2cdVufvT288btbX/D32xyvAhf1A96+BsvXtXlyDxoYqeSaBVfPmzTFlyhT13GQyoVKlSnj55ZcxalTuUfG1a9cQEhKC1SuXwNc/ABkJ0YhP90SMFoBrMdH4L8EbUZ7l4eVhRJgWjeaJGxDnHY4EnzK4LXEXyicdQVRQfVwJqo1LJZvC6OWr5i0TdwiVL6yCX8olnC9xBxJ8y6Js9DZ4ZSTgXOgdOFOqNdKNPtCgISjhFAKTzyMs7hAyjF64EFgPHqYUBMQewZ8nNcxPbqHKKgHFYyVPqBN8YPpVlZ3YcM6I06ZSCDPEwhMZ2IRGaFwpFD4Zibg9cTuueYUh2SMIgelXkJYUj8PxfkiCD1LgjTOaOQPgg1Q0N0bC28OAWI+SSE5NRVlEIwMeOK+VRLQWgssIgZeHAaW901Ar5QBqGM7hshaMdHhgnNf3KGOIQZLmjW6p7yJSq6yW29NjLY6YKuI24xlUMlzEIVMVtbwmxn/RsEETPNzzOWw8dAr15t6FEoZ4/J1RD8e08njaYxWMBg2/ZNyD99J6IwZBanmNDUfR0HgMHYy7cAVBWJzRCuUM0bjbuB9LMlriD1NrNd+7njORASO2m2rjWc8VaGGMxFZTHewy1cIk0+MIDvDHpbhkdDTuwAuei1HNEIVVnm1w1Pt2PJC2BiGmGEzB4/gzvamqiurosQuVPK+iuiEKHRMXwWTwxN+BEbjsUwl7KvSCj6cRtWM2oE7MBtS4tg1XfSpgR5keCE/8FzVjt2BpnQ+QEloDVc4tQ6fIN3HWrzY2BUWg9eX5KG86j52mWng/rTd2abep8gcaUzGt5FzcmbgW3qZknCrTDiYPP5SL3ozV9y5AgndpBJ5ciZaHJyDD4IG95R9HuOkSbj87H6k+JXCsziAcKfcwYlPNLR4e2tYbpWIPWD7zsSXqYVu7Oah0cgHq7ByLVJ+Sqm1EUlBV7OrwMzzT4tDq97bwTE9AYmAVXA1vhQrH5qj3xpWoi133/Yh0z0Dctuv/EBD7r5qnwvF50AxGXAlvjSMNXkVcaB0VK5U5+ycabxkGo2bOHJ6rEKE+91vrvo0keMP72mm02zcS4fEHcdGvBraG9UCj6CWonHgAmz2bY0TCU+pzWtFwCTP8pqJUw44I3/8NkJ4EVGwOVGsLtH9bBfYDv1yMiQljUMt4Vq1rr6ka6hhPY3+1/ijdZSy8Yv5FyaUD4R19CJrRE3F3vAxDyjX4HV+O6M7fIC28ETxiT6LkyqFIDW+M5Mpt4Xv6L3hd3IeU8i2RXqI6km7raj5BaBp8T6xCwIGf4BF/Dkk1H0JaqTrw/W8VDGmJSK4egaRaXcw7XNPgc/ovGJOvwvfkOpi8ApBcrT0MGanwvvAPkqrdj7SyTdSs/gfnwZCehNQyDeF19Si8og8jLbQ60kvVgTHpslquvkz/A7PhGXcWqaXrIiO4MjxjjsOYEov0EjWRHlIFGUEVrs9rgve5rfA9uV5dxZVS4U54XT6MgINzYPIORFzzIUiu3hF+h39FqRUvIbnKvfCIOQmv2BPQPLxxrfkQxLUYajkxGhMuwPvCHnjEnUNGcCWkB1WER8J5GJNjkBFYDqnlW1oaNHvEnIAxLQkecafV9qYHVzLvh1Mb1PJiW79lmdf3+ApkBJRVwbox8TI0Tx+Y/MJgSEuA5umH9FLmHsENKbHwP7wQGYFlkR5aTa3XmHwFJr9SMPmWgOblf2Pb05PhfXGf2qcmv5LQPHxgTIqGwZSODJk/IFxN1/epZ3QkPJIuq8+yyT8Mhox0tWzZDxlBFZEhgcJ1nlePwZAar7ZH8w6CyTcUhpQ4dQwygiuo46DzurhXlcuYGH29LKWgefqqsmjegUgrbQ4k5LPjHbUbGf5h6rh5yI8go6d6bjBlwOQdgIyQKte3LQk+Z7eq5co2yLI9Ei6oxxmyXVKmwLI3lntuu1pfRlB5mHxC4Rn7n/nzElIZaWF1ofmEWPaD9/kd8Lq0T+2n1DINYJT3n9mifgSpz3pp8w8Ur0sH4X1uG4J2fwnP2JPQYIABGi48sRyG9GSU+aWbZR9c7vwNwpb0V4/jG/VDzL3vI2j7FwjZZA7CLvRagbQyDVFyyXPwP7rEfD73CUVc4+fUZ1WWd+mx35BewvxDziPuLOLi4lG7flPExsYiODgYecUgK49SU1Ph7++PX375Bd263TiYffr0QUxMDH7//fcs70lJSVE36yBLgrLYUUEI9sl6+feM9M74IL23elzTcAarfEbmWJ6nU0fhL1ND9fgdz5no47ky2/nSNSOapnyFawhQz+d5v6MCgezICXhEyMe4HJeCa8lp2O/TH4GG7Kt3Nnrdhd5xL6nHIYjHP77P51jWJd4RmOw3GP9FJyIk/Qq2+76Y47z7Kz+FJ04+rLJgtQ2nsMIna/CaAD8c8qqHD0u8gzIhfqiincfrR837LVuPzQLqPWLexjnvo9nhCVlmSTH6Y2LN7xGZFKyOzScnH4NvWky2ixvuMQor0pqgfKgfBnktRvfoGdnOl3DPGPi0HYal+6MQsupVtI1bmu18vVLfxGZTPfX4D+830dB4Itv5XkkdjEsIxfdeH8LLkLXK85ipHNqnfqyCGE+k47DPs/A0ZL0K7njt57G6wiD8eTAKDU7/jDFeP2T7uRme9iL+MN2FBobjWOTzVrZluqSFoE3KJCTDBw0Nx/CHz9tq+ltpffGm50/qM/Va2kBcQTDW+QxDecMV9fq7aU/j24xO6vFAjz8wysscWOniNV8sN7VQ7y2Dq1jrMxwBhhv/S7r/TOF4OPU9pMALa3xeRQVDNCJNFVHdcN6yjyakPY5pGd3gixQ1j14Ga3Gan9qO8uUqYLLnZNS6lP3/Ex76HGjWBykbp8Nn5ShcQyCgZSDYkKReXpzREi+nvYxxnt+p/8kUzQs+hhtV4FK2iNSP1DHyQAY2+7ysfjRkp0/q61hvaqQeL/J+Aw2M/2U7358ZzfB82qvqcQ3DWaz2GZF92TN91l7znIuXPLN+b4kEzQeNU75G2vXKjlXer6Gm8Vy2827IaIBn0kZbnq/3HooqRnPGO7MxaX3wfUYE7jfuwBSvLyz7JlHzgb8hRa1Xvq/kh5n4zGsqHvG4Xu2cSbQWhGYpX1me/+b9Fhobj2c77w7TbXg0dZx6bIQJh3z62hwXawszWmNY2uA8fbfNSu+IcenPqsfyY3GL78t5mtcPyTjk2y/HeX/LuAtD017K07zW5c1t3gUZd6v/a1EaMTf9Lv4hvQPeTjcvS/4Ht/ma15Gdb9I74f/Sn1aPqxrOY52P+fOYnQlpPTEto6t6XB6Xscn3FeTkzbR++Cmjg3r8udcXeNhjs3osiYlQQ4JlvgdSPsTy6+eKq1ogmqTMwH++T6rnqzOaoH/aCET69LEc86rJP1t+TH/p/RkuayGob/X/Jd8r7VI/gXa9RdV2n0G4lqKh5kdn8h1ksbowjy5fvoyMjAyEh4fbTJfnhw8fzvY948ePxzvvvJNl+jUEQTN4IMEjCN5IR4ApDmmeAbirRnlMuL0h0jJMSE+9DSf23oeApPMISj6H84H1cSagHipc243wpKPoVsGE0iEVVMPcK3EPYPu1DFzxKqsySkEZMTjq1whJHoHwN8XjvvK1VPWcUTOhyvEkRGtlccbvdnhqKaiUFIk0gw8u+FWHV+XWWNm9rarCW/vPUSSvrwrPpLNI9CqBBL9yKG2IhW/CeSCwDFq37I71Ne7FrlNX4efpgZi/WsAn/iw8064h1TcM8A6AX8plGNOT0Ll+BXTu0hYmk4a4xBSkz/oCJk1Tv4QMRg8YQiqqX064dgb1S2Rg5zMdVNXNtfhEpC+YBY/SNWFIuATEnALqdEHA/e/gDs2EX6RqSZzbA2S0hSYp39K3AyWrwXTuHxjjzsFQoRlQqaVl3zfr+QZw5Qlg8TBAlhnxPuAdCJ/Y03ir/v3mma7+B3wXAvhVAer3AGLPmuv6g8KB6u3waZthgJfv9Q9GeWDdFXMjSqn+avYssHMWcGSF6iUcHkY8XFnSPHthaj0c0SUawXf3N/C8dgqXKndCcmgtjKn3KPy8PZGWlga/Pc8g/sg8pBp8sKv6IHilxaPR8em45lcJtWr2QpOEU7gWWQlxPmWwK7wHysUfQJ3o1bjiWxm7yvTA0wFVVdWqj6cHPjcswn1R36LW1fW4VKMHAlo8jdK7p6D6mdWo/ui7GHBPdcTMnom4k+Wxumx/HEY1dL0wFcHp0ZhZciiuetdFW4MBIX7lsdA4CSXSolDn7K+Igx9+9emBsLSzSDL6o3loBVU92zT+MKIvlsG6wE74178nPk6ugYGxn6NriQvY4l0d36a8iP4J/8Ma73bYWaI76hm8VGLhb603emrdMDDhS9ROj8Q3AQNwzLMmkgx+aGT0V6e6EemfY3D85yov+m3AAHgjFX3iv8VV75JoWiYQwVocTDH+2ODVEDNChqBO2gE8FzsF/3nfhqsVu+BBv7JqnyxM/QAZ3kG4M/p31L26GkdL349T5SJQ3Tcey1t0U9XZSKhrbjx7Zhtw72hzFkvab8jnQKpTTSb4/LdGTQ965CtoGekw/f4izqcH4ov4F1EhNhp3ekRipak53jX1RQvDQQw3zsFRrSJ+1CJUNtKc9zNirOk5dDVsQFPDv9il1cJOrQ7aGP5RP7KqeETD53p153daF9Q1ncBxrTy6G9erE+TfWkP142kPal1fJlDREINTWhkVpGzQGiMQibjbsBfJ8MY+rQYOG2tZlrkOzdHUdAx1DCdxCuE4pFVFdcNZ1MIZlSEu6xmPizBnXhZo7VDTdBp1Df8hHFdxAmVxTQtUQV1Z41XL+gOQBGllsNB0j+qNqLnhMGIRiNmmDiiBOCw23Kvm3YAW6JfxBt7z+Ar/aLXwvqkPOhm2oK9xMep7nsV+SAZBQyPjCRzSJCsdhoqGC2rdUSiplhmjBVrWK7wMJnXyPYMySIUXKuISUuGBrVp9rNbusMxbAvHYg5qoqZ1V2ZBoBMMbaQhDLBLhi2SDn2XeZARjkam12i+VcBExCMRVBKEk4hCKOPgYTZZ54xGq9r3sa9lWX6SqHxcSqJaUb31jqmXecCSqYEBeN0JTr0tGXJbthXREGUpb5i2NJMRrfkiAr1p/IJIQinjEIgBx8McplLfMG4ZkXNBKIADJKgMvNQmybClLNEJwFFUs8yYgRGXz5XX5PF5CiCqLfLak1kBqOqznlc+EP5LVtkk5L6KEelwaV+FrzLDMexnhOKJVVPOUxRVV1tMog2tagKplqOxxGT7XM5W1DBdwUSuBA1pVpMMTdQ0n1H7YptVV+2GboaFlucdRCWe1f7FHq6X+b+4x7MErxvmYa2qPEx5V0S9jNN4xfoOJpifVe57PGInRxh8wVXtMPR9jeg79jYswPGOIZZmHcBvuz5gMT5gwEVNQ3XAOP5o64i+tMbw9b4RH8iMutYD9azGTlUfnzp1DhQoVsGnTJrRq1coyfeTIkVi/fj22bt2a90xWPiNhIiIich29uQ8zWQ4SFhYGDw8PXLhwwWa6PC9b1lwXnZmPj4+6ERER0a2HXTjkkbe3N5o1a4bVq1dbpknDd3lundkiIiIiEsxk5YN03yAN3e+44w60aNFCdeGQkJCAvn37urpoRERE5GYYZOVDz549cenSJYwZMwZRUVFo3Lgxli9fnqUxPBEREREbvheBhnNERERU9M7fbJNFRERE5AAMsoiIiIgcgEEWERERkQMwyCIiIiJyAAZZRERERA7AIIuIiIjIARhkERERETkAgywiIiIiB2CQRUREROQAHFbHifTO9aXnWCIiIioa9PN2fgfJYZDlRNHR0eq+UqVKri4KERER5VNcXJwaXievGGQ5UcmSJdX9qVOn8nWQyL6/RiTIPX36NMePdBEeA/fA4+B6PAZF5xhIBksCrPLly+dr+QyynMhoNDeBkwCL/1CuJfufx8C1eAzcA4+D6/EYFI1jUJDkCBu+ExERETkAgywiIiIiB2CQ5UQ+Pj4YO3asuifX4DFwPR4D98Dj4Ho8BsX/GBi0/F6PSERERES5YiaLiIiIyAEYZBERERE5AIMsIiIiIgdgkEVERETkAAyynGTq1KmoWrUqfH190bJlS2zbts3VRSq2xo0bB4PBYHOrU6eO5fXk5GQMHjwYpUqVQmBgIHr06IELFy64tMzFwYYNG/DQQw+pHpFln//22282r8s1NmPGjEG5cuXg5+eHDh064N9//7WZ58qVK+jdu7fqFDA0NBT9+/dHfHy8k7ek+B6DZ599Nsv/xgMPPGAzD49B4YwfPx7NmzdHUFAQypQpg27duiEyMtJmnrx8B8nIIJ07d4a/v79azogRI5Cenu7krSm+x+Dee+/N8r8wcOBAux8DBllOMHfuXAwfPlxdJrpr1y40atQIERERuHjxoquLVmzVq1cP58+ft9z+/vtvy2vDhg3DokWLMH/+fKxfvx7nzp1D9+7dXVre4iAhIUF9tuUHRXYmTJiAzz//HF9++SW2bt2KgIAA9X8gJxydnNwPHDiAlStXYvHixSpoeP755524FcX7GAgJqqz/N2bPnm3zOo9B4ch3igRQW7ZsUfswLS0NHTt2VMcmr99BGRkZ6uSempqKTZs24bvvvsOsWbPUjxSyzzEQAwYMsPlfkO8oux8D6cKBHKtFixba4MGDLc8zMjK08uXLa+PHj3dpuYqrsWPHao0aNcr2tZiYGM3Ly0ubP3++ZdqhQ4ekGxNt8+bNTixl8Sb7c+HChZbnJpNJK1u2rDZx4kSbY+Hj46PNnj1bPT948KB63/bt2y3zLFu2TDMYDNrZs2edvAXF7xiIPn36aF27ds3xPTwG9nfx4kW1T9evX5/n76ClS5dqRqNRi4qKsswzffp0LTg4WEtJSXHBVhSvYyDatm2rDRkyRMuJvY4BM1kOJlHwzp07VdWI9RiG8nzz5s0uLVtxJtVQUmVSvXp19ctc0r5CjoX8qrE+HlKVWLlyZR4PBzpx4gSioqJs9ruMAyZV5/p+l3upnrrjjjss88j88v8imS+yj3Xr1qmqj9q1a2PQoEGIjo62vMZjYH+xsbHqvmTJknn+DpL7Bg0aIDw83DKPZH1lMGPJMlLhjoHup59+QlhYGOrXr4/Ro0cjMTHR8pq9jgEHiHawy5cvq7Sj9YES8vzw4cMuK1dxJiduSevKSURSwO+88w7atGmD/fv3qxO9t7e3OpFkPh7yGjmGvm+z+z/QX5N7Oflb8/T0VF+MPDb2IVWFUi1VrVo1HDt2DG+88QY6deqkTigeHh48BnZmMpkwdOhQtG7dWp3IRV6+g+Q+u/8V/TUq3DEQTz75JKpUqaJ+jO/duxevv/66are1YMECux4DBllU7MhJQ9ewYUMVdMk/07x581SDa6Jb1RNPPGF5LL/S5f+jRo0aKrvVvn17l5atOJJ2QfLjzrpNKLnHMbBuZyj/C3JBjvwPyI8P+Z+wF1YXOpikIuUXYuYrR+R52bJlXVauW4n8Yrzttttw9OhRtc+lCjcmJsZmHh4Px9L37c3+D+Q+88UgciWPXO3GY+MYUp0u31HyvyF4DOznpZdeUhcOrF27FhUrVrRMz8t3kNxn97+iv0aFOwbZkR/jwvp/wR7HgEGWg0lauFmzZli9erVN+lKet2rVyqVlu1XI5efy60R+qcix8PLysjkekiKWNls8Ho4j1VPyxWS936Vtg7Tz0fe73MuJR9qs6NasWaP+X/QvQLKvM2fOqDZZ8r8heAwKT645kJP7woUL1b6Tz761vHwHyf2+fftsAl65Sk661ahbt64Tt6Z4HoPs7NmzR91b/y/Y5RjkuYk8FdicOXPUVVSzZs1SV+88//zzWmhoqM1VC2Q/r776qrZu3TrtxIkT2saNG7UOHTpoYWFh6goTMXDgQK1y5cramjVrtB07dmitWrVSNyqcuLg4bffu3eomXy2ffvqpenzy5En1+ocffqg+97///ru2d+9edZVbtWrVtKSkJMsyHnjgAa1Jkyba1q1btb///lurVauW1qtXLxduVfE5BvLaa6+9pq5gk/+NVatWaU2bNlX7ODk52bIMHoPCGTRokBYSEqK+g86fP2+5JSYmWubJ7TsoPT1dq1+/vtaxY0dtz5492vLly7XSpUtro0ePdtFWFa9jcPToUe3dd99V+17+F+Q7qXr16to999xj92PAIMtJvvjiC/VP5e3trbp02LJli6uLVGz17NlTK1eunNrXFSpUUM/ln0onJ/UXX3xRK1GihObv76898sgj6h+QCmft2rXqxJ75Jt0G6N04vP3221p4eLj60dG+fXstMjLSZhnR0dHqhB4YGKgule7bt68KDqjwx0BOMHLCkBOFdCFQpUoVbcCAAVl+7PEYFE52+19uM2fOzNd30H///ad16tRJ8/PzUz8S5cdjWlqaC7ao+B2DU6dOqYCqZMmS6ruoZs2a2ogRI7TY2Fi7HwPD9QIRERERkR2xTRYRERGRAzDIIiIiInIABllEREREDsAgi4iIiMgBGGQREREROQCDLCIiIiIHYJBFRERE5AAMsoiIihkZ8NlgMGQZH4+InItBFhEVaVFRURgyZAhq1qwJX19fhIeHo3Xr1pg+fToSExNdUqaqVati0qRJLlk3EbkPT1cXgIiooI4fP64CqtDQUHzwwQdo0KABfHx81MCuM2bMQIUKFfDwww9n+960tDQ1UC8RkaMwk0VERdaLL74IT09P7NixA48//jhuv/12VK9eHV27dsWSJUvw0EMPWeaV6jPJbknQFRAQgPfffx8ZGRno378/qlWrBj8/P9SuXRuTJ0+2vGfDhg0qEJNsmbWhQ4eiTZs2BS7377//jqZNm6rMm5T3nXfeQXp6unrtySefRM+ePbMEhGFhYfj+++/Vc5PJhPHjx1vK3ahRI/zyyy8FLg8ROQaDLCIqkqKjo/Hnn39i8ODBKmjKjgRW1saNG4dHHnlEZbr69eungpWKFSti/vz5OHjwIMaMGYM33ngD8+bNU/Pfc889Kgj64YcfbAKen376Sb2/IP766y8888wzqopT1vnVV19h1qxZKugTvXv3xqJFixAfH295z4oVK1TVp5RdSIAlAdeXX36JAwcOYNiwYXjqqaewfv36ApWJiBzEjgNfExE5zZYtW2Rwe23BggU200uVKqUFBASo28iRIy3TZd6hQ4fmutzBgwdrPXr0sDz/6KOPtNtvv93y/Ndff9UCAwO1+Pj4HJdRpUoV7bPPPsv2tfbt22sffPCBzbQffvhBK1eunHqclpamhYWFad9//73l9V69emk9e/ZUj5OTkzV/f39t06ZNNsvo37+/mk+sXbtWbe/Vq1dz3V4ichxmsoioWNm2bRv27NmDevXqISUlxea1O+64I8v8U6dORbNmzVC6dGkEBgaqtlynTp2yvP7ss8/i6NGj2LJli3ouWSepmswpe5abf/75B++++65al34bMGAAzp8/r7JVUv0py5dsmUhISFDVi5LhElIWme/++++3WYZkto4dO1agMhGRY7DhOxEVSXI1oVQHRkZG2kyX6j0hbZUyyxwYzZkzB6+99ho++eQTtGrVCkFBQZg4cSK2bt1qmadMmTKqbdfMmTNVG6hly5apLhIKSqoBpQ1W9+7ds7wmbbSEBFRt27bFxYsXsXLlSrUtDzzwgOX9QtqcScN+a9Lon4jcB4MsIiqSSpUqpbI5U6ZMwcsvv1ygzNLGjRtx1113qQb0uuyyQc899xx69eql2m/VqFFDXdFYUNLgXQJDCRJzImWqVKkS5s6dq4K6xx57zHIlZN26dVUwJdk2CcSIyH0xyCKiImvatGkq4JFqQGnU3rBhQxiNRmzfvh2HDx9W1YA3U6tWLVXNJg3LJUslDdzlvfLYWkREBIKDg/Hee++pqr68OHv2rKq2tFalShXVuL5Lly6oXLkyHn30UVVeqULcv3+/Wr5OrjKUhu1HjhzB2rVrLdMl2ybZN2nsLg337777bsTGxqqAUcrYp0+fPO49InI4B7b3IiJyuHPnzmkvvfSSVq1aNc3Ly0s1Sm/RooU2ceJELSEhwTKffN0tXLjQ5r3SiPzZZ5/VQkJCtNDQUG3QoEHaqFGjtEaNGmVZz9tvv615eHio9eVGGr7L+jLfpIG7WL58uXbXXXdpfn5+WnBwsCrvjBkzbJZx8OBB9R5ZlslksnlNnk+aNEmrXbu22ubSpUtrERER2vr169XrbPhO5B4M8sfxoRwRUdEm/WldunQJf/zxh6uLQkRFBKsLiYhuQqripF+tn3/+mQEWEeULgywiopuQ3uOlW4iBAweqhvZERHnF6kIiIiIiB2BnpEREREQOwCCLiIiIyAEYZBERERE5AIMsIiIiIgdgkEVERETkAAyyiIiIiByAQRYRERGRAzDIIiIiInIABllEREREsL//BxvXEUnNhriZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty histogram array of size 256 (for 256 grayscale levels)\n",
    "# np.uint16 is used to handle large counts, depending on the image size\n",
    "histo1 = np.zeros((256, 1), np.uint16)\n",
    "\n",
    "# Manually compute the histogram of the original (darkened) image\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        histo1[img[y, x], 0] += 1\n",
    "\n",
    "# Use OpenCVâ€™s built-in function to calculate histogram of the normalized image\n",
    "histo2 = cv2.calcHist([imgNorm], [0], None, [256], [0, 255])\n",
    "\n",
    "# Plot both histograms using Matplotlib\n",
    "plt.figure()\n",
    "plt.title(\"Normalized Image Histogram\")\n",
    "plt.xlabel(\"Gray Level\")\n",
    "plt.ylabel(\"Number of Pixels\")\n",
    "\n",
    "# Plot the manually computed histogram for the original image\n",
    "plt.plot(histo1, label=\"Original Image (Manual Histogram)\")\n",
    "\n",
    "# Plot the OpenCV-computed histogram for the normalized image\n",
    "plt.plot(histo2, label=\"Normalized Image (cv2.calcHist)\", linestyle='dashed')\n",
    "\n",
    "# Limit x-axis to valid grayscale range\n",
    "plt.xlim([0, 255])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HISTOGRAM EXAMPLE 2 â€“ Visualizing Horizontal and Vertical Projections ===\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "# Load the grayscale image\n",
    "img = cv2.imread('sadcat.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply binary thresholding: pixels > 130 become 255, others become 0\n",
    "cv2.threshold(img, 130, 255, cv2.THRESH_BINARY, img)\n",
    "\n",
    "# Get image dimensions\n",
    "h, w = img.shape \n",
    "\n",
    "# Initialize arrays to count black pixels per row and column\n",
    "lignes = np.zeros((h), np.uint16)  # Horizontal projection (per row)\n",
    "cols = np.zeros((w), np.uint16)    # Vertical projection (per column)\n",
    "\n",
    "# Count black pixels (value = 0) in each row and column\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        if img[i, j] == 0:\n",
    "            lignes[i] += 1\n",
    "            cols[j] += 1\n",
    "\n",
    "# Create white images to visualize horizontal and vertical projections\n",
    "imgLignes = np.full(img.shape, 255, dtype=np.uint8)\n",
    "imgCols = np.full(img.shape, 255, dtype=np.uint8)\n",
    "\n",
    "# Draw black lines in each row based on the count of black pixels\n",
    "for i in range(h):\n",
    "    for j in range(lignes[i]):\n",
    "        imgLignes[i, j] = 0\n",
    "\n",
    "# Draw black lines in each column based on the count of black pixels\n",
    "for j in range(w):\n",
    "    for i in range(cols[j]):\n",
    "        imgCols[i, j] = 0\n",
    "\n",
    "# Display the original and the histogram visualizations side by side\n",
    "cv2.imshow(\"Source Image\", img)\n",
    "cv2.imshow(\"Horizontal Projection (Row Histogram)\", cv2.hconcat([img, imgLignes]))\n",
    "cv2.imshow(\"Vertical Projection (Column Histogram)\", cv2.hconcat([img, imgCols]))\n",
    "\n",
    "# Wait for a key press and close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# === EXERCISE 3 â€“ Random Point Movement on a Binary Image ===\n",
    "\n",
    "# Function to create an image with all white pixels and a single black pixel at a random location\n",
    "def createImgWithPointRand(h, w):\n",
    "    img = np.ones((h, w), np.float32)  # Create a white image (all values = 1.0)\n",
    "    randPointY, randPointX = randrange(h), randrange(w)  # Choose a random point\n",
    "    img[randPointY, randPointX] = 0  # Set that random point to black (0.0)\n",
    "    return img\n",
    "\n",
    "# Function to find the position of the black pixel (value = 0) in the image\n",
    "def findBlackPixel(img):\n",
    "    h, w = img.shape\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if img[y, x] == 0:\n",
    "                return (y, x)\n",
    "\n",
    "# === Image configuration ===\n",
    "heightImg = 200\n",
    "widthImg = 400\n",
    "step = 3  # Number of pixels to move each time\n",
    "\n",
    "# Create the initial image and locate the black pixel\n",
    "img = createImgWithPointRand(heightImg, widthImg)\n",
    "(py, px) = findBlackPixel(img)\n",
    "\n",
    "# Initialize input key\n",
    "q = 'a'\n",
    "\n",
    "# === Main interaction loop ===\n",
    "while True:\n",
    "    # Down arrow key (ASCII 50): move the black pixel downward\n",
    "    if q == 50 and py + step < heightImg:\n",
    "        img[py, px] = 1\n",
    "        img[py + step, px] = 0\n",
    "        py = py + step\n",
    "\n",
    "    # Up arrow key (ASCII 56): move the black pixel upward\n",
    "    if q == 56 and py - step >= 0:\n",
    "        img[py, px] = 1\n",
    "        img[py - step, px] = 0\n",
    "        py = py - step\n",
    "\n",
    "    # Left arrow key (ASCII 52): move the black pixel to the left\n",
    "    if q == 52 and px - step >= 0:\n",
    "        img[py, px] = 1\n",
    "        img[py, px - step] = 0\n",
    "        px = px - step\n",
    "\n",
    "    # Right arrow key (ASCII 54): move the black pixel to the right\n",
    "    if q == 54 and px + step < widthImg:\n",
    "        img[py, px] = 1\n",
    "        img[py, px + step] = 0\n",
    "        px = px + step\n",
    "\n",
    "    # Display the updated image\n",
    "    cv2.imshow('Image', img)\n",
    "\n",
    "    # Wait for a key press and get its ASCII code (only the last byte)\n",
    "    q = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # Press '0' to quit the loop (ASCII code of '0' is 48)\n",
    "    if ord('0') == q:\n",
    "        break\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 3 â€“ Smoothing Filters: Mean and Median '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.shape_base import vsplit\n",
    "\n",
    "# Load the image in grayscale mode\n",
    "image_path = 'sadcat.jpeg'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Size of the neighborhood (must be odd)\n",
    "vois = 3  # Kernel size (3x3 neighborhood)\n",
    "\n",
    "# === Mean Filter ===\n",
    "def filtreMoy(img):\n",
    "    h, w = img.shape\n",
    "    imgMoy = np.zeros(img.shape, img.dtype)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            # Skip pixels near the border to avoid out-of-bounds access\n",
    "            if y < vois/2 or y > (h - vois/2) or x < vois/2 or x > (w - vois/2):\n",
    "                imgMoy[y, x] = img[y, x]\n",
    "            else:\n",
    "                m = int(vois / 2)\n",
    "                # Extract the neighborhood (voisinage)\n",
    "                imgVois = img[y - m:y + m + 1, x - m:x + m + 1]\n",
    "                # Compute the mean and assign it to the current pixel\n",
    "                imgMoy[y, x] = np.mean(imgVois)\n",
    "    return imgMoy\n",
    "\n",
    "# === Median Filter ===\n",
    "def filtreMedian(img):\n",
    "    h, w = img.shape\n",
    "    imgMed = np.zeros(img.shape, img.dtype)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            # Skip border pixels\n",
    "            if y < vois/2 or y > (h - vois/2) or x < vois/2 or x > (w - vois/2):\n",
    "                imgMed[y, x] = img[y, x]\n",
    "            else:\n",
    "                m = int(vois / 2)\n",
    "                # Extract the neighborhood\n",
    "                imgVois = img[y - m:y + m + 1, x - m:x + m + 1]\n",
    "                # Compute the median and assign it to the current pixel\n",
    "                imgMed[y, x] = np.median(imgVois)\n",
    "    return imgMed\n",
    "\n",
    "# Apply filters to the image\n",
    "imgMoy = filtreMoy(image)\n",
    "imgMed = filtreMedian(image)\n",
    "\n",
    "# Display original and filtered images\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Mean Filtered Image\", imgMoy)\n",
    "cv2.imshow(\"Median Filtered Image\", imgMed)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 4 â€“ Interactive Image Thresholding with Trackbars '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# === Load the grayscale image ===\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initial threshold value and type\n",
    "th = 0           # Threshold level (0 to 255)\n",
    "type_th = 0      # Thresholding method (OpenCV types 0 to 4)\n",
    "\n",
    "# === Function to apply thresholding and display the result ===\n",
    "def afficher():\n",
    "    # Create an output image with the same shape and type as input\n",
    "    imgRes = np.zeros_like(img)\n",
    "\n",
    "    # Apply thresholding using OpenCV's built-in function\n",
    "    # Parameters:\n",
    "    # - img: input grayscale image\n",
    "    # - th: threshold value\n",
    "    # - 255: maximum value to use\n",
    "    # - type_th: thresholding type (e.g., binary, inverse, trunc, etc.)\n",
    "    # - imgRes: destination image\n",
    "    cv2.threshold(img, th, 255, type_th, imgRes)\n",
    "\n",
    "    # Show the result in a window\n",
    "    cv2.imshow('img', imgRes)\n",
    "\n",
    "# === Callback function: updates threshold value ===\n",
    "def change_th(x):\n",
    "    global th\n",
    "    th = x\n",
    "    afficher()\n",
    "\n",
    "# === Callback function: updates thresholding method ===\n",
    "def change_type(x):\n",
    "    global type_th\n",
    "    type_th = x\n",
    "    afficher()\n",
    "\n",
    "# Initial display of the image\n",
    "afficher()\n",
    "\n",
    "# === Create trackbars ===\n",
    "\n",
    "# Threshold value trackbar: lets user choose a threshold between 0 and 255\n",
    "cv2.createTrackbar(\"thresh\", \"img\", 0, 256, change_th)\n",
    "\n",
    "# Thresholding type trackbar: choose among 5 OpenCV thresholding modes\n",
    "# 0: Binary\n",
    "# 1: Binary Inverse\n",
    "# 2: Truncate\n",
    "# 3: To Zero\n",
    "# 4: To Zero Inverse\n",
    "cv2.createTrackbar(\"type\", \"img\", 0, 4, change_type)\n",
    "\n",
    "# Wait for a key press before closing the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Gradient-Based Edge Detection with Interactive Thresholding '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# === Load the image in grayscale ===\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initial threshold value for edge detection\n",
    "th = 0\n",
    "\n",
    "# === Function to compute and display the edge map ===\n",
    "def afficher():\n",
    "    # Create an empty image to store the contours (edges)\n",
    "    imgContour = np.zeros_like(img)  # Same size and type as the original\n",
    "\n",
    "    # Compute the gradient in the X direction (horizontal difference)\n",
    "    grad_x = img[:, :img.shape[1] - 1] - img[:, 1:]\n",
    "\n",
    "    # Compute the gradient in the Y direction (vertical difference)\n",
    "    grad_y = img[:img.shape[0] - 1, :] - img[1:, :]\n",
    "\n",
    "    # Pad gradients to match the original image size\n",
    "    grad_x = np.pad(grad_x, ((0, 0), (0, 1)), mode='constant')  # Pad last column\n",
    "    grad_y = np.pad(grad_y, ((0, 1), (0, 0)), mode='constant')  # Pad last row\n",
    "\n",
    "    # Compute the gradient magnitude (Euclidean norm)\n",
    "    grad = np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "    # Apply threshold: highlight edges where gradient magnitude > th\n",
    "    imgContour[grad > th] = 255  # Strong edge\n",
    "    imgContour[grad <= th] = 0   # Weak or no edge\n",
    "\n",
    "    # Display the resulting edge image\n",
    "    cv2.imshow('img', imgContour)\n",
    "\n",
    "# === Callback function to update the threshold from the trackbar ===\n",
    "def change_th(x):\n",
    "    global th\n",
    "    th = x\n",
    "    afficher()\n",
    "\n",
    "# Create the display window\n",
    "cv2.namedWindow(\"img\")\n",
    "\n",
    "# Create a trackbar to adjust the threshold value\n",
    "cv2.createTrackbar(\"thresh\", \"img\", 0, 256, change_th)\n",
    "\n",
    "# Initial display\n",
    "afficher()\n",
    "\n",
    "# Wait for key press before closing\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.00 \t4.00 \t5.00 \t4.00 \t2.00 \t\n",
      "4.00 \t9.00 \t12.00 \t9.00 \t4.00 \t\n",
      "5.00 \t12.00 \t15.00 \t12.00 \t5.00 \t\n",
      "4.00 \t9.00 \t12.00 \t9.00 \t4.00 \t\n",
      "2.00 \t4.00 \t5.00 \t4.00 \t2.00 \t\n",
      "Sum = 159.0\n",
      "2.0 4.0 5.0 4.0 2.0\n",
      "4.0 9.0 12.0 9.0 4.0\n",
      "5.0 12.0 15.0 12.0 5.0\n",
      "4.0 9.0 12.0 9.0 4.0\n",
      "2.0 4.0 5.0 4.0 2.0\n"
     ]
    }
   ],
   "source": [
    "# === Section 1: Gaussian Blur (Smoothing) ===\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load grayscale image\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a 3x3 Gaussian kernel\n",
    "kernel = np.array([[1, 2, 1],\n",
    "                   [2, 4, 2],\n",
    "                   [1, 2, 1]]) / 16\n",
    "\n",
    "# Apply the Gaussian filter using convolution\n",
    "imgRes = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "# Normalize the result to the 0â€“255 range\n",
    "cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Display the original and filtered image\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Gaussian Blurred\", imgRes)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 2: Laplacian Filtering + Edge Enhancement ===\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image in grayscale\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a Laplacian kernel (edge detection)\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 4, -1],\n",
    "                   [0, -1, 0]])\n",
    "\n",
    "# Apply convolution\n",
    "imgRes = cv2.filter2D(img.astype(np.int16), -1, kernel)\n",
    "\n",
    "# Add the result to the original image to enhance edges\n",
    "imgRes = img + imgRes\n",
    "\n",
    "# Normalize and display\n",
    "cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Laplacian Enhanced\", imgRes.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 3: Custom Gradient Kernel + Enhancement ===\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load grayscale image\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a simple custom gradient kernel\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 1, -1],\n",
    "                   [0, -1, 0]])\n",
    "\n",
    "# Apply filter and enhance result\n",
    "imgRes = cv2.filter2D(img.astype(np.int16), -1, kernel)\n",
    "imgRes = img + imgRes\n",
    "\n",
    "# Normalize and display\n",
    "cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Gradient Enhanced\", imgRes.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 4: Sharpening with Laplacian Kernel ===\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load grayscale image\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Sharpening kernel (Laplacian + identity)\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5, -1],\n",
    "                   [0, -1, 0]])\n",
    "\n",
    "# Apply sharpening filter\n",
    "imgRes = cv2.filter2D(img.astype(np.int16), -1, kernel)\n",
    "\n",
    "# Normalize and display\n",
    "cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Sharpened\", imgRes.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 5: Gaussian Kernel Generator and Display ===\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute the Gaussian value for coordinates (x, y)\n",
    "def gauss(x, y, sigma):\n",
    "    part1 = 1 / (2 * math.pi * sigma**2)\n",
    "    part2 = -((x**2 + y**2) / (2 * sigma**2))\n",
    "    return part1 * math.exp(part2)\n",
    "\n",
    "# Print and view Gaussian kernel\n",
    "def print_gauss(sigma=1.4, vois_mat=5):\n",
    "    vois = vois_mat // 2\n",
    "    som = 0.0\n",
    "    for i in range(-vois, vois + 1):\n",
    "        for j in range(-vois, vois + 1):\n",
    "            val = round(gauss(i, j, sigma) * 185, 0)\n",
    "            print('{:02.2f}'.format(val), '\\t', end=\"\")\n",
    "            som += val\n",
    "        print('')\n",
    "    print('Sum =', som)\n",
    "\n",
    "print_gauss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 6: Return the Gaussian kernel as a NumPy matrix ===\n",
    "\n",
    "def check_gauss(mat):\n",
    "    for row in mat:\n",
    "        print(\" \".join(map(str, row)))\n",
    "\n",
    "def get_gauss(sigma=1.4, vois_mat=5):\n",
    "    mat_gauss = np.zeros((vois_mat, vois_mat), float)\n",
    "    vois = vois_mat // 2\n",
    "    som = 0.0\n",
    "    for i in range(-vois, vois + 1):\n",
    "        for j in range(-vois, vois + 1):\n",
    "            val = round(gauss(i, j, sigma) * 185, 0)\n",
    "            mat_gauss[i + vois][j + vois] = val\n",
    "            som += val\n",
    "    return som, mat_gauss\n",
    "\n",
    "som, mat_gauss = get_gauss()\n",
    "check_gauss(mat_gauss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Section 7: Apply Custom Gaussian Kernel ===\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load grayscale image\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Generate Gaussian kernel\n",
    "som, kernel = get_gauss()\n",
    "\n",
    "# Apply the kernel as a filter\n",
    "imgRes = cv2.filter2D(img.astype(np.int16), -1, kernel)\n",
    "\n",
    "# Normalize and display result\n",
    "cv2.normalize(imgRes, imgRes, 0, 255, cv2.NORM_MINMAX)\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Gaussian Filtered (Custom)\", imgRes.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
   ],
   "source": [
    "''' TP 6 â€“ Morphological Operations with Trackbars (Erosion, Dilation, Gradient) '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# === Load the grayscale image ===\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert to binary image using a fixed threshold\n",
    "cv2.threshold(img, 128, 255, cv2.THRESH_BINARY, img)\n",
    "\n",
    "# Create a window for each operation\n",
    "cv2.namedWindow(\"Erosion\")\n",
    "cv2.namedWindow(\"Dilation\")\n",
    "cv2.namedWindow(\"Morph Gradient\")\n",
    "\n",
    "# === Initial sizes for structuring elements (adjusted by trackbars) ===\n",
    "sizeErode = 1\n",
    "sizeDilate = 1\n",
    "sizeMorph = 1\n",
    "\n",
    "# === Erosion Function ===\n",
    "def erode_func():\n",
    "    size = sizeErode * 2 + 1  # Ensure odd kernel size (e.g., 3, 5, 7...)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))\n",
    "    print(\"Erode kernel:\\n\", kernel)\n",
    "    img_erode = cv2.erode(img, kernel)\n",
    "    cv2.imshow(\"Erosion\", img_erode)\n",
    "\n",
    "# === Dilation Function ===\n",
    "def dilate_func():\n",
    "    size = sizeDilate * 2 + 1\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))\n",
    "    print(\"Dilate kernel:\\n\", kernel)\n",
    "    img_dilate = cv2.dilate(img, kernel)\n",
    "    cv2.imshow(\"Dilation\", img_dilate)\n",
    "\n",
    "# === Morphological Gradient Function ===\n",
    "def morph_func():\n",
    "    size = sizeMorph * 2 + 1\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))\n",
    "    print(\"Morph Gradient kernel:\\n\", kernel)\n",
    "    # Morph gradient = dilation - erosion\n",
    "    img_morph = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "    cv2.imshow(\"Morph Gradient\", img_morph)\n",
    "\n",
    "# === Trackbar callbacks ===\n",
    "def changeErodeSize(x):\n",
    "    global sizeErode\n",
    "    sizeErode = x\n",
    "    erode_func()\n",
    "\n",
    "def changeDilateSize(x):\n",
    "    global sizeDilate\n",
    "    sizeDilate = x\n",
    "    dilate_func()\n",
    "\n",
    "def changeMorphSize(x):\n",
    "    global sizeMorph\n",
    "    sizeMorph = x\n",
    "    morph_func()\n",
    "\n",
    "# === Create trackbars to adjust structuring element size dynamically ===\n",
    "cv2.createTrackbar(\"Erode Size\", \"Erosion\", sizeErode, 17, changeErodeSize)\n",
    "cv2.createTrackbar(\"Dilate Size\", \"Dilation\", sizeDilate, 17, changeDilateSize)\n",
    "cv2.createTrackbar(\"Morph Size\", \"Morph Gradient\", sizeMorph, 17, changeMorphSize)\n",
    "\n",
    "# === Show the original binary image ===\n",
    "cv2.imshow(\"Original Binary\", img)\n",
    "\n",
    "# === Initial display ===\n",
    "erode_func()\n",
    "dilate_func()\n",
    "morph_func()\n",
    "\n",
    "# === Wait until key is pressed ===\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 7 '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# === Read the original color image ===\n",
    "image_path = 'sadcat.jpeg'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Create empty images for each color channel with the same shape and type as original\n",
    "img_b = np.zeros(img.shape, img.dtype)\n",
    "img_g = np.zeros(img.shape, img.dtype)\n",
    "img_r = np.zeros(img.shape, img.dtype)\n",
    "\n",
    "# Get image dimensions\n",
    "h, w, c = img.shape\n",
    "\n",
    "'''\n",
    "# Method 1: Manual pixel-wise assignment (commented out for performance)\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        img_b[y,x,0] = img[y,x,0]\n",
    "        img_g[y,x,1] = img[y,x,1]\n",
    "        img_r[y,x,2] = img[y,x,2]\n",
    "'''\n",
    "\n",
    "# Method 2: Efficient slicing to separate channels\n",
    "img_b[:, :, 0], img_g[:, :, 1], img_r[:, :, 2] = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "\n",
    "'''\n",
    "# Compute grayscale manually using channel weighting:\n",
    "# Grayscale = 0.1*Blue + 0.6*Green + 0.3*Red\n",
    "# Using weights helps avoid truncation and keeps float precision\n",
    "'''\n",
    "\n",
    "# Basic grayscale computation using equal contribution from each channel\n",
    "img_gray = (np.float32(img_b[..., 0]) + \n",
    "            np.float32(img_g[..., 1]) + \n",
    "            np.float32(img_r[..., 2])) / 3\n",
    "\n",
    "# Optional: Normalize grayscale to [0, 1] for floating point visualization\n",
    "img_gray = img_gray / 255  # (or divide by 3*255 if weights used)\n",
    "\n",
    "# Convert BGR image to HLS color space (Hue, Lightness, Saturation)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "# Convert original image to float representation in range [0, 1]\n",
    "img_float = img / 255\n",
    "\n",
    "# === Display results ===\n",
    "cv2.imshow(\"image B\", img_b)\n",
    "cv2.imshow(\"image G\", img_g)\n",
    "cv2.imshow(\"image R\", img_r)\n",
    "cv2.imshow(\"image gray\", img_gray)\n",
    "cv2.imshow(\"image hsv\", img_hsv)\n",
    "cv2.imshow(\"image float\", img_float)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 8 â€“ Video Sampling and Recording '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "# === Capture source ===\n",
    "# Choose one of the following:\n",
    "# cap = cv2.VideoCapture(0)                       # 1. For webcam\n",
    "# cap = cv2.VideoCapture('output.avi')           # 2. From a saved video\n",
    "# url = \"http://192.168.226.189:8080/video\"      \n",
    "# cap = cv2.VideoCapture(url)                    # 3. IP camera (mobile phone via IP Webcam app)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # â† Example: using webcam\n",
    "\n",
    "# === Get frame dimensions ===\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# === Check if capture opened successfully ===\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video source.\")\n",
    "    exit(0)\n",
    "\n",
    "# === Video writer (output file with XVID codec, 30 fps) ===\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output2.avi', fourcc, 30, (frame_width, frame_height))\n",
    "\n",
    "# === Frame reading loop ===\n",
    "while cap.isOpened():\n",
    "\n",
    "    debut = time.time()  # Time before reading the frame\n",
    "\n",
    "    ret, frame = cap.read()  # Read a frame\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Optional: Flip the frame (uncomment if needed)\n",
    "    # frame = cv2.flip(frame, 0)\n",
    "\n",
    "    out.write(frame)              # Save the frame to the output file\n",
    "    cv2.imshow(\"image\", frame)    # Display the frame\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "    # Print time per frame and FPS\n",
    "    time_iter = time.time() - debut\n",
    "    print(\"time =\", round(time_iter, 4), \"s | fps =\", round(1. / time_iter, 2))\n",
    "\n",
    "# === Release resources ===\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
   ],
   "source": [
    "''' TP 9 '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Uncomment this line to use your phone's IP webcam\n",
    "# url = \"http://192.168.226.189:8080/video\"\n",
    "# VideoCap = cv2.VideoCapture(url)\n",
    "\n",
    "# Use default webcam (computer camera)\n",
    "VideoCap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define HSV color range for detection (example: blue object)\n",
    "lo = np.array([95, 80, 60])      # Lower HSV bound\n",
    "hi = np.array([115, 255, 255])   # Upper HSV bound\n",
    "\n",
    "# Optional: set up video recording\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('recorded_output.avi', fourcc, 30, (640, 480))\n",
    "\n",
    "# === Function to detect objects within HSV range ===\n",
    "def detect_inrange(image, min, max):\n",
    "    points = []\n",
    "    image = cv2.blur(image, (5, 5))  # Blur to reduce noise\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # Convert to HSV\n",
    "\n",
    "    # Create mask from HSV range\n",
    "    mask = cv2.inRange(image, lo, hi)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, None, iterations=2)  # Clean mask\n",
    "\n",
    "    # Find contours\n",
    "    elements = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    elements = sorted(elements, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\n",
    "    for element in elements:\n",
    "        area = int(cv2.contourArea(element))\n",
    "        if min < area < max:\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(element)\n",
    "            points.append(np.array([int(x), int(y), int(radius), area]))\n",
    "\n",
    "    return image, mask, points\n",
    "\n",
    "# === Verify capture is working ===\n",
    "if not VideoCap.isOpened():\n",
    "    print(\"Error: Cannot open video stream.\")\n",
    "    exit(0)\n",
    "\n",
    "# === Main loop ===\n",
    "while True:\n",
    "    ret, frame = VideoCap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    cv2.flip(frame, 1, frame)  # Flip horizontally\n",
    "\n",
    "    image, mask, points = detect_inrange(frame, 1000, 3000)\n",
    "\n",
    "    # Debug point\n",
    "    cv2.circle(frame, (100, 100), 20, (0, 255, 0), 5)\n",
    "    print(image[100, 100])\n",
    "\n",
    "    # Draw circle and info if any point found\n",
    "    if len(points) > 0:\n",
    "        cv2.circle(frame, (points[0][0], points[0][1]), points[0][2], (0, 0, 255), 2)\n",
    "        cv2.putText(frame, str(points[0][3]), (points[0][0], points[0][1]),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display mask and frame\n",
    "    if mask is not None:\n",
    "        cv2.imshow(\"mask\", mask)\n",
    "\n",
    "    cv2.imshow(\"image\", frame)\n",
    "    out.write(frame)  # Save to video file\n",
    "\n",
    "    # Press 'q' to stop\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "VideoCap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TP 10 : Kalman Filter Tracking '''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, dt, point):\n",
    "        self.dt = dt  # Time step\n",
    "\n",
    "        # Initial state vector [x, y, vx, vy]\n",
    "        self.E = np.matrix([[point[0]], [point[1]], [0], [0]])\n",
    "\n",
    "        # State transition matrix (A)\n",
    "        self.A = np.matrix([\n",
    "            [1, 0, self.dt, 0],\n",
    "            [0, 1, 0, self.dt],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "        # Observation matrix (we only observe position x, y)\n",
    "        self.H = np.matrix([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ])\n",
    "\n",
    "        # Process noise covariance (Q)\n",
    "        self.Q = np.matrix([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "\n",
    "        # Measurement noise covariance (R)\n",
    "        self.R = np.matrix([\n",
    "            [1, 0],\n",
    "            [0, 1]\n",
    "        ])\n",
    "\n",
    "        # Initial estimation error covariance (P)\n",
    "        self.P = np.eye(4)\n",
    "\n",
    "    def predict(self):\n",
    "        # Predict the next state\n",
    "        self.E = self.A @ self.E\n",
    "\n",
    "        # Update error covariance\n",
    "        self.P = self.A @ self.P @ self.A.T + self.Q\n",
    "\n",
    "        return self.E\n",
    "\n",
    "    def update(self, z):\n",
    "        # Compute Kalman Gain\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "\n",
    "        # Update estimate with measurement z\n",
    "        self.E = np.round(self.E + K @ (z - self.H @ self.E))\n",
    "\n",
    "        # Update error covariance\n",
    "        I = np.eye(self.H.shape[1])\n",
    "        self.P = (I - K @ self.H) @ self.P\n",
    "\n",
    "        return self.E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[430 225]\n",
      " [826 621]]\n",
      "[[434 223]\n",
      " [819 608]]\n",
      "[[444 235]\n",
      " [806 597]]\n",
      "[[440 229]\n",
      " [813 602]]\n",
      "[[431 221]\n",
      " [811 601]]\n",
      "[[431 218]\n",
      " [804 591]]\n",
      "[[436 224]\n",
      " [804 592]]\n",
      "[[432 219]\n",
      " [812 599]]\n",
      "[[430 218]\n",
      " [802 590]]\n",
      "[[428 215]\n",
      " [816 603]]\n",
      "[[425 215]\n",
      " [814 604]]\n",
      "[[430 226]\n",
      " [799 595]]\n",
      "[[420 212]\n",
      " [827 619]]\n",
      "[[414 217]\n",
      " [822 625]]\n",
      "[[424 230]\n",
      " [810 616]]\n",
      "[[414 217]\n",
      " [817 620]]\n",
      "[[433 228]\n",
      " [815 610]]\n",
      "[[434 225]\n",
      " [821 612]]\n",
      "[[434 231]\n",
      " [812 609]]\n",
      "[[429 222]\n",
      " [820 613]]\n",
      "[[429 222]\n",
      " [820 613]]\n",
      "[[443 229]\n",
      " [807 593]]\n",
      "[[445 195]\n",
      " [812 562]]\n",
      "[[457 166]\n",
      " [814 523]]\n",
      "[[462 158]\n",
      " [804 500]]\n",
      "[[478 159]\n",
      " [819 500]]\n",
      "[[517 142]\n",
      " [856 481]]\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "[[483 175]\n",
      " [828 520]]\n",
      "[[444 168]\n",
      " [811 535]]\n",
      "[[436 186]\n",
      " [802 552]]\n",
      "[[437 184]\n",
      " [798 545]]\n",
      "[[432 185]\n",
      " [794 547]]\n",
      "[[422 183]\n",
      " [787 548]]\n",
      "[[426 188]\n",
      " [782 544]]\n",
      "[[418 182]\n",
      " [781 545]]\n",
      "[[421 189]\n",
      " [780 548]]\n",
      "[[422 190]\n",
      " [778 546]]\n",
      "[[417 186]\n",
      " [775 544]]\n",
      "[[418 188]\n",
      " [778 548]]\n",
      "[[410 182]\n",
      " [783 555]]\n",
      "[[418 189]\n",
      " [774 545]]\n",
      "[[418 189]\n",
      " [776 547]]\n",
      "[[389 195]\n",
      " [744 550]]\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "erreur\n",
      "[[338 164]\n",
      " [733 559]]\n",
      "erreur\n",
      "[[361 204]\n",
      " [706 549]]\n",
      "[[348 192]\n",
      " [718 562]]\n",
      "erreur\n",
      "[[344 200]\n",
      " [714 570]]\n",
      "[[342 194]\n",
      " [712 564]]\n",
      "[[351 194]\n",
      " [721 564]]\n",
      "[[343 178]\n",
      " [728 563]]\n",
      "[[348 185]\n",
      " [730 567]]\n",
      "[[343 178]\n",
      " [728 563]]\n",
      "[[406 184]\n",
      " [767 545]]\n",
      "[[464 169]\n",
      " [838 543]]\n",
      "[[470 174]\n",
      " [828 532]]\n",
      "[[447 179]\n",
      " [814 546]]\n",
      "[[426 168]\n",
      " [803 545]]\n"
     ]
    }
   ],
   "source": [
    "''' TP 11 : Face Detection with Kalman Filter '''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# HSV range for optional object detection (e.g., blue object)\n",
    "lo = np.array([95, 100, 30])\n",
    "hi = np.array([125, 255, 255])\n",
    "\n",
    "# Function to detect objects in a specific HSV color range\n",
    "def detect_inrange(image, surfaceMin, surfaceMax):\n",
    "    points = []\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # Convert to HSV\n",
    "    image = cv2.blur(image, (5, 5))                 # Blur to reduce noise\n",
    "    mask = cv2.inRange(image, lo, hi)               # Threshold in range\n",
    "    mask = cv2.erode(mask, None, iterations=2)      # Morphological erosion\n",
    "    mask = cv2.dilate(mask, None, iterations=2)     # Morphological dilation\n",
    "\n",
    "    # Detect contours in the mask\n",
    "    elements = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    elements = sorted(elements, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\n",
    "    for element in elements:\n",
    "        print('Surface :', cv2.contourArea(element))\n",
    "        if surfaceMin < cv2.contourArea(element) < surfaceMax:\n",
    "            ((x, y), rayon) = cv2.minEnclosingCircle(element)\n",
    "            points.append(np.array([int(x), int(y)]))\n",
    "            break\n",
    "\n",
    "    return points, mask\n",
    "\n",
    "# Function to detect faces using Haar cascade classifier\n",
    "def detect_visage(image):\n",
    "    # Load OpenCV built-in Haar cascade XML\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n",
    "    \n",
    "    if face_cascade.empty():\n",
    "        print(\"Failed to load Haar cascade XML file.\")\n",
    "        exit()\n",
    "\n",
    "    points = []\n",
    "    rects = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3)\n",
    "\n",
    "    for x, y, w, h in face:\n",
    "        points.append(np.array([int(x + w / 2), int(y + h / 2)]))\n",
    "        rects.append(np.array([(x, y), (x + w, y + h)]))\n",
    "\n",
    "    return points, rects\n",
    "\n",
    "\n",
    "# Open webcam stream\n",
    "VideoCap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Kalman Filter with timestep = 0.1s and initial position [10,10]\n",
    "KF = KalmanFilter(0.1, [10, 10])\n",
    "\n",
    "while True:\n",
    "    mask = None\n",
    "    rects = None\n",
    "\n",
    "    ret, frame = VideoCap.read()  # Read frame from webcam\n",
    "\n",
    "    cv2.flip(frame, 1, frame)     # Mirror the frame (optional for user-facing cameras)\n",
    "\n",
    "    # Uncomment if using color range detection:\n",
    "    # points, mask = detect_inrange(frame, 3000, 7000)\n",
    "\n",
    "    points, rects = detect_visage(frame)  # Use face detection instead\n",
    "\n",
    "    etat = KF.predict().astype(np.int32)  # Predict next position with Kalman filter\n",
    "\n",
    "    # Draw predicted position (green)\n",
    "    cv2.circle(frame, (int(etat[0]), int(etat[1])), 2, (0, 255, 0), 5)\n",
    "\n",
    "    # Draw velocity vector (green arrow)\n",
    "    cv2.arrowedLine(\n",
    "        frame,\n",
    "        (int(etat[0]), int(etat[1])),\n",
    "        (int(etat[0] + etat[2]), int(etat[1] + etat[3])),\n",
    "        color=(0, 255, 0),\n",
    "        thickness=3,\n",
    "        tipLength=0.2\n",
    "    )\n",
    "\n",
    "    # If a new measurement is available (face detected)\n",
    "    if len(points) > 0:\n",
    "        KF.update(np.expand_dims(points[0], axis=-1))  # Update Kalman filter\n",
    "        cv2.circle(frame, (points[0][0], points[0][1]), 10, (0, 0, 255), 2)  # Draw measured position (red)\n",
    "\n",
    "    # Draw face rectangle if detected\n",
    "    if rects is not None:\n",
    "        try:\n",
    "            print(rects[0])\n",
    "            cv2.rectangle(frame, rects[0][0], rects[0][1], (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        except:\n",
    "            print(\"erreur\")\n",
    "\n",
    "    # Show the mask (only if color detection was used)\n",
    "    if mask is not None:\n",
    "        cv2.imshow('mask', mask)\n",
    "\n",
    "    # Show the result frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Exit on key 'q'\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "VideoCap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP ðŸ’¡ Replace 'model=yolo-Weights/yolov5n.pt' with new 'model=yolo-Weights/yolov5nu.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5nu.pt to 'yolo-Weights/yolov5nu.pt'...\n",
      "âš ï¸ Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5nu.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 94.0ms\n",
      "Speed: 2.1ms preprocess, 94.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 60.4ms\n",
      "Speed: 1.2ms preprocess, 60.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.0ms\n",
      "Speed: 1.3ms preprocess, 64.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 51.2ms\n",
      "Speed: 1.3ms preprocess, 51.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 51.5ms\n",
      "Speed: 1.2ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.0ms\n",
      "Speed: 1.2ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.5ms\n",
      "Speed: 1.1ms preprocess, 56.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.1ms\n",
      "Speed: 1.1ms preprocess, 56.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 52.7ms\n",
      "Speed: 1.1ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.2ms\n",
      "Speed: 1.2ms preprocess, 54.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.1ms\n",
      "Speed: 1.3ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.3ms\n",
      "Speed: 1.2ms preprocess, 59.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 52.4ms\n",
      "Speed: 1.3ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 52.4ms\n",
      "Speed: 1.0ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 49.2ms\n",
      "Speed: 1.2ms preprocess, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 52.7ms\n",
      "Speed: 1.3ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 56.3ms\n",
      "Speed: 1.7ms preprocess, 56.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 50.1ms\n",
      "Speed: 1.2ms preprocess, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 57.8ms\n",
      "Speed: 1.2ms preprocess, 57.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 62.0ms\n",
      "Speed: 4.8ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 50.9ms\n",
      "Speed: 1.0ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 56.4ms\n",
      "Speed: 1.2ms preprocess, 56.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 52.5ms\n",
      "Speed: 1.3ms preprocess, 52.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.7ms\n",
      "Speed: 1.1ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 47.3ms\n",
      "Speed: 1.7ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 47.3ms\n",
      "Speed: 0.9ms preprocess, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 46.1ms\n",
      "Speed: 1.4ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 55.9ms\n",
      "Speed: 1.3ms preprocess, 55.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 53.0ms\n",
      "Speed: 1.1ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 51.0ms\n",
      "Speed: 1.2ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 3 cell phones, 50.6ms\n",
      "Speed: 1.6ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 257.3ms\n",
      "Speed: 2.9ms preprocess, 257.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 2 cell phones, 54.6ms\n",
      "Speed: 1.2ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 2 cell phones, 58.9ms\n",
      "Speed: 1.1ms preprocess, 58.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 63.3ms\n",
      "Speed: 1.5ms preprocess, 63.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 cell phones, 60.8ms\n",
      "Speed: 1.4ms preprocess, 60.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 81.9ms\n",
      "Speed: 1.3ms preprocess, 81.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 67.6ms\n",
      "Speed: 1.3ms preprocess, 67.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 65.8ms\n",
      "Speed: 1.2ms preprocess, 65.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 237.4ms\n",
      "Speed: 8.2ms preprocess, 237.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 91.5ms\n",
      "Speed: 1.5ms preprocess, 91.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 67.0ms\n",
      "Speed: 1.3ms preprocess, 67.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 224.7ms\n",
      "Speed: 10.4ms preprocess, 224.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 232.4ms\n",
      "Speed: 3.3ms preprocess, 232.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 242.4ms\n",
      "Speed: 13.9ms preprocess, 242.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 263.0ms\n",
      "Speed: 2.6ms preprocess, 263.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 260.0ms\n",
      "Speed: 3.2ms preprocess, 260.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 204.6ms\n",
      "Speed: 2.2ms preprocess, 204.6ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 150.9ms\n",
      "Speed: 5.7ms preprocess, 150.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 260.5ms\n",
      "Speed: 2.7ms preprocess, 260.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 257.9ms\n",
      "Speed: 2.4ms preprocess, 257.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.5ms\n",
      "Speed: 1.1ms preprocess, 56.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 54.6ms\n",
      "Speed: 1.3ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 246.8ms\n",
      "Speed: 3.4ms preprocess, 246.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 61.7ms\n",
      "Speed: 2.1ms preprocess, 61.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 61.7ms\n",
      "Speed: 1.6ms preprocess, 61.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 62.0ms\n",
      "Speed: 1.6ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.8ms\n",
      "Speed: 1.5ms preprocess, 58.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bed, 54.9ms\n",
      "Speed: 1.3ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.4ms\n",
      "Speed: 1.1ms preprocess, 58.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 55.6ms\n",
      "Speed: 1.1ms preprocess, 55.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 59.7ms\n",
      "Speed: 1.4ms preprocess, 59.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 56.6ms\n",
      "Speed: 1.4ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 54.9ms\n",
      "Speed: 1.1ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 59.8ms\n",
      "Speed: 1.4ms preprocess, 59.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.5ms\n",
      "Speed: 2.0ms preprocess, 56.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.5ms\n",
      "Speed: 1.7ms preprocess, 56.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.4ms\n",
      "Speed: 1.6ms preprocess, 75.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.8ms\n",
      "Speed: 1.1ms preprocess, 58.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 57.4ms\n",
      "Speed: 1.0ms preprocess, 57.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.9ms\n",
      "Speed: 1.7ms preprocess, 59.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.1ms\n",
      "Speed: 1.1ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 62.4ms\n",
      "Speed: 1.2ms preprocess, 62.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.3ms\n",
      "Speed: 1.5ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.6ms\n",
      "Speed: 1.8ms preprocess, 61.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.8ms\n",
      "Speed: 1.2ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 51.6ms\n",
      "Speed: 1.4ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 50.9ms\n",
      "Speed: 1.4ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.7ms\n",
      "Speed: 1.8ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.9ms\n",
      "Speed: 2.0ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 52.8ms\n",
      "Speed: 1.1ms preprocess, 52.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.4ms\n",
      "Speed: 2.0ms preprocess, 55.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.9ms\n",
      "Speed: 1.7ms preprocess, 60.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.8ms\n",
      "Speed: 1.1ms preprocess, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.1ms\n",
      "Speed: 1.7ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.6ms\n",
      "Speed: 1.1ms preprocess, 70.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.1ms\n",
      "Speed: 1.3ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.8ms\n",
      "Speed: 1.3ms preprocess, 58.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.2ms\n",
      "Speed: 1.2ms preprocess, 54.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.9ms\n",
      "Speed: 1.2ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 57.5ms\n",
      "Speed: 1.1ms preprocess, 57.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 61.7ms\n",
      "Speed: 1.7ms preprocess, 61.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.7ms\n",
      "Speed: 2.1ms preprocess, 58.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.9ms\n",
      "Speed: 1.2ms preprocess, 64.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.7ms\n",
      "Speed: 1.7ms preprocess, 68.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.5ms\n",
      "Speed: 1.3ms preprocess, 68.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.8ms\n",
      "Speed: 2.1ms preprocess, 64.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.8ms\n",
      "Speed: 1.2ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 65.5ms\n",
      "Speed: 2.5ms preprocess, 65.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.6ms\n",
      "Speed: 1.7ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 62.5ms\n",
      "Speed: 1.9ms preprocess, 62.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.0ms\n",
      "Speed: 1.6ms preprocess, 53.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 63.6ms\n",
      "Speed: 1.4ms preprocess, 63.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 65.5ms\n",
      "Speed: 1.0ms preprocess, 65.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.7ms\n",
      "Speed: 1.8ms preprocess, 64.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.0ms\n",
      "Speed: 1.4ms preprocess, 69.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 62.8ms\n",
      "Speed: 1.8ms preprocess, 62.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 68.7ms\n",
      "Speed: 1.3ms preprocess, 68.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.7ms\n",
      "Speed: 1.7ms preprocess, 64.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.8ms\n",
      "Speed: 1.4ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.7ms\n",
      "Speed: 1.2ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.4ms\n",
      "Speed: 7.7ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 64.1ms\n",
      "Speed: 1.4ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.5ms\n",
      "Speed: 1.2ms preprocess, 53.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.4ms\n",
      "Speed: 1.5ms preprocess, 55.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.3ms\n",
      "Speed: 2.4ms preprocess, 53.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.6ms\n",
      "Speed: 1.7ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 57.6ms\n",
      "Speed: 1.7ms preprocess, 57.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.3ms\n",
      "Speed: 1.4ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 51.5ms\n",
      "Speed: 1.1ms preprocess, 51.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.3ms\n",
      "Speed: 2.0ms preprocess, 58.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.4ms\n",
      "Speed: 1.3ms preprocess, 54.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.4ms\n",
      "Speed: 1.5ms preprocess, 58.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.6ms\n",
      "Speed: 1.0ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 48.4ms\n",
      "Speed: 1.3ms preprocess, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.1ms\n",
      "Speed: 1.3ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.7ms\n",
      "Speed: 1.8ms preprocess, 72.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.3ms\n",
      "Speed: 0.9ms preprocess, 54.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.0ms\n",
      "Speed: 1.7ms preprocess, 59.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.2ms\n",
      "Speed: 1.4ms preprocess, 60.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.2ms\n",
      "Speed: 1.0ms preprocess, 54.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.6ms\n",
      "Speed: 1.7ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.6ms\n",
      "Speed: 1.0ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.4ms\n",
      "Speed: 1.8ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.6ms\n",
      "Speed: 1.2ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.6ms\n",
      "Speed: 1.3ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.0ms\n",
      "Speed: 1.8ms preprocess, 53.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 50.9ms\n",
      "Speed: 1.0ms preprocess, 50.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.7ms\n",
      "Speed: 1.3ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 57.4ms\n",
      "Speed: 1.4ms preprocess, 57.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 56.1ms\n",
      "Speed: 2.4ms preprocess, 56.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 58.2ms\n",
      "Speed: 1.2ms preprocess, 58.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 53.7ms\n",
      "Speed: 1.3ms preprocess, 53.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 60.8ms\n",
      "Speed: 1.1ms preprocess, 60.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.3ms\n",
      "Speed: 1.4ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.7ms\n",
      "Speed: 1.3ms preprocess, 59.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 55.9ms\n",
      "Speed: 1.1ms preprocess, 55.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.2ms\n",
      "Speed: 1.8ms preprocess, 59.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 54.9ms\n",
      "Speed: 1.3ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 59.1ms\n",
      "Speed: 1.1ms preprocess, 59.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "'''tp 12 : cell phone detection'''\n",
    "import cv2 # manipulate frames and video (display)\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort # to use the model of track \n",
    "from ultralytics import YOLO # to use yolo to track \n",
    "\n",
    "\n",
    "# Set environment variable to avoid duplicate library errors\n",
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "# Initialize the DeepSort tracker (une instance )\n",
    "''' \n",
    "DeepSort uses :\n",
    "    Kalman Filters & Hungarian Algorithm for { association and prediction }\n",
    "    Neural network for { appearance-based re-identification }\n",
    "It ensures consistent tracking of objects \n",
    "    [even when they temporarily disappear from view or when the camera moves slightly]\n",
    "Each tracked object is assigned\n",
    "    a unique ID (to monitor that object)\n",
    "'''\n",
    "object_tracker = DeepSort()\n",
    "\n",
    "# Initialize the YOLO model (version 8) with a smaller model for faster inference\n",
    "# Use yolov5n for faster inference\n",
    "# DETAILS \n",
    "'''\n",
    "model = YOLO(weights, task=None, mode=None)\n",
    "weights (Required):\n",
    "    path to the custom model weights\n",
    "        Pretrained YOLOv8 weights:\n",
    "            \"yolov8'c'.pt\": c => can be ,n(nano) ,s(small) ,m(medium) ,l(large) ,x(extra large)\n",
    "task (Optional):\n",
    "    Specifies the task the model is meant to perform:\n",
    "        \"detect\": Object detection (default if not specified).\n",
    "        \"segment\": Instance segmentation.\n",
    "        \"classify\": Image classification.\n",
    "mode (Optional):\n",
    "    Specifies the mode of operation:\n",
    "        \"train\": Train a new or custom YOLO model.\n",
    "        \"val\": Validate the performance of the model on a dataset.\n",
    "        \"predict\": Make predictions on images or videos (default).\n",
    "        \"export\": Export the model for inference (e.g., ONNX, TensorRT, etc.).\n",
    "\n",
    "default : \n",
    "- model = YOLO(\"yolov8n-seg.pt/yolov8n.pt\")\n",
    "    Default task : \"segment\".\n",
    "    Default mode: \"predict\".\n",
    "- model = YOLO(\"yolov8n-cls.pt/yolov8n.pt\")\n",
    "    Default task : \"classify\".\n",
    "    Default mode: \"predict\".\n",
    "'''\n",
    "model = YOLO(\"yolo-Weights/yolov5n.pt\")  \n",
    "\n",
    "\n",
    "# code to start the webcam ( 0 => the actual default camera , in my case my laptop)\n",
    "# DETAILS \n",
    "'''\n",
    "cap = cv2.VideoCapture(source, apiPreference)\n",
    "READING of the video frame by frame \n",
    "Parameters:\n",
    "    source (required):\n",
    "        Specifies the video source.\n",
    "        Integer: Refers to the index of the camera.\n",
    "            0: Default camera \n",
    "            1: Second connected camera, and so on.\n",
    "        String: Path to a video file \n",
    "apiPreference (optional):\n",
    "Specifies which API backend to use (e.g., DirectShow, Media Foundation, etc.).\n",
    "Common values include:\n",
    "cv2.CAP_ANY (default): Auto-select the backend.\n",
    "cv2.CAP_DSHOW: DirectShow (Windows).\n",
    "cv2.CAP_AVFOUNDATION: AVFoundation (macOS).\n",
    "'''\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# these lines is to define the capture of cam width and the height \n",
    "# DETAILS \n",
    "'''\n",
    "cap.set(id number ,pixels values )\n",
    "- '3' => CAP_PROP_FRAME_WIDTH the video frame width in pixels.\n",
    "- '4' => CAP_PROP_FRAME_HEIGHT the video frame height in pixels.\n",
    "'''\n",
    "cap.set(3, 640)  \n",
    "cap.set(4, 480)  \n",
    "\n",
    "# Read class names from the model (reads all the classes that are available on the yolo model)\n",
    "# DETAILS\n",
    "'''\n",
    "COCO dataset\n",
    "model.names is a dictionnary : \n",
    "    {\n",
    "        (key: \"value\",)\n",
    "        0: \"person\",\n",
    "        1: \"bicycle\",\n",
    "        2: \"car\",\n",
    "        ...\n",
    "        79: \"toothbrush\"\n",
    "    }\n",
    "'''\n",
    "classNames = model.names  \n",
    "\n",
    "# just take the index of the object we want to detect , in our case , cell phone => 67\n",
    "phone_class_index = 67  \n",
    "\n",
    "# this line ensures that the web cam is indeed opened \n",
    "while cap.isOpened():\n",
    "    '''\n",
    "    cap.read() returns :\n",
    "        success: A boolean  frame was successfully read or not .\n",
    "        img: The actual frame (image) if success is true .\n",
    "    '''\n",
    "    success, img = cap.read()\n",
    "\n",
    "    '''cas frame not read sortir '''\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # DETAILS\n",
    "    '''\n",
    "    img is the frame we read \n",
    "    the stream value \n",
    "        The stream=True means  'YOLO' will return results as a generator(with streaming)\n",
    "    means :\n",
    "        Instead of returning all detections at once in one frame it returns a set of results that way we can manipulate each as we want , it is also memory saving\n",
    "    '''\n",
    "    '''\n",
    "    here:\n",
    "        preprocessing \n",
    "            resizing the frame to treat it with yolo \n",
    "            normalisation ect \n",
    "        inference \n",
    "            runing cnn of yolo to detect \n",
    "        steaming \n",
    "            already explained \n",
    "    '''\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # Prepare a list to store detections for DeepSORT\n",
    "    detections = []\n",
    "\n",
    "    # Process results from YOLO\n",
    "    '''\n",
    "    for each results r we will have : \n",
    "        Bounding Box (r.boxes.xyxy):\n",
    "            (x1, y1, x2, y2).\n",
    "        Class Index (r.boxes.cls):\n",
    "            The index of the detected class \n",
    "        Confidence (r.boxes.conf):\n",
    "            The confidence score for the detection of the class (proba)\n",
    "    '''\n",
    "    # iterate all the results \n",
    "    for r in results:\n",
    "        # retrieve the box detection result of all objects \n",
    "        boxes = r.boxes\n",
    "        # this to only detect a phone \n",
    "        # iterate all the boxes \n",
    "        for box in boxes:\n",
    "            # retrieve the classe of detection \n",
    "            cls = int(box.cls[0])  \n",
    "\n",
    "            # If the detected class is 'cell phone'\n",
    "            '''do traitement , detection + tracking '''\n",
    "            if cls == phone_class_index:\n",
    "                '''get the coordinates'''\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                '''\n",
    "                    float to int\n",
    "                    because : \n",
    "                        Image pixels are discrete and indexed using integers.\n",
    "                '''\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Calculate the center of the bounding box\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "\n",
    "                # Add detection to list for DeepSORT (bbox, confidence, class)\n",
    "                detections.append(([x1, y1, x2, y2], box.conf[0], cls))\n",
    "\n",
    "                # DISPLAY \n",
    "                '''\n",
    "                display rectangle \n",
    "                cv2.rectangle ( frame , the coordinate top left , bottom right , color line rectangle , border thickness)\n",
    "                display a circle \n",
    "                cv2.circle(frame , coordinate of center , radius of circle,color ,circle filled or no (with color))\n",
    "                '''\n",
    "                # Draw bounding box \n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "                cv2.circle(img, (center_x, center_y), 5, (0, 255, 0), -1) \n",
    "                ''' \n",
    "                this to display the center x and y (position of the object)\n",
    "                '''\n",
    "                # Display the center position as text on the webcam\n",
    "                center_text = f\"Center: ({center_x}, {center_y})\"\n",
    "                org = (x1, y1 - 10)  \n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 0.7\n",
    "                color = (0, 255, 0)\n",
    "                thickness = 2\n",
    "                ''' \n",
    "                cv2.putText(frame , text ,where to display (position),font, fontScale, color, thickness)\n",
    "                '''\n",
    "                cv2.putText(img, center_text, org, font, fontScale, color, thickness)\n",
    "\n",
    "\n",
    "    # Pass detections to DeepSORT for tracking\n",
    "    # track the object \n",
    "    ''' \n",
    "    Matching Detections to Existing Tracks:\n",
    "        DeepSort attempts to match the new detections (detections) to previously tracked objects using:\n",
    "            Bounding box overlap (Intersection over Union, IoU).\n",
    "            Appearance features (if enabled).\n",
    "        Updating Tracks:\n",
    "            For matched detections, DeepSort updates the state of the corresponding track .\n",
    "        Creating New Tracks:\n",
    "            If a detection cannot be matched to an existing track, DeepSort adds it.\n",
    "        Removing Lost Tracks:\n",
    "            Tracks that have not been updated for multiple frames => delete.\n",
    "        \n",
    "        Return Value:\n",
    "            tracks: A list of track objects\n",
    "            track_id: ID\n",
    "            to_ltrb(): The bounding box coordinates [left, top, right, bottom] of the tracked object.\n",
    "            is_confirmed(): A flag indicating whether the track is active and confirmed.\n",
    "            Optionally, additional information\n",
    "    '''\n",
    "    tracks = object_tracker.update_tracks(detections, frame=img)\n",
    "\n",
    "    # Draw a moving dot for each track (phone)\n",
    "    for track in tracks:\n",
    "        \n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "\n",
    "        # Calculate the center of the bounding box for the dot\n",
    "        center_x = int((ltrb[0] + ltrb[2]) // 2)\n",
    "        center_y = int((ltrb[1] + ltrb[3]) // 2)\n",
    "\n",
    "        # Draw the dot at the center of the tracked phone object\n",
    "        cv2.circle(img, (center_x, center_y), 5, (0, 0, 255), -1)  # Red dot for tracking\n",
    "\n",
    "    \n",
    "\n",
    "    # Display the image on webcam with all the added displays \n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # press q to quit \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
